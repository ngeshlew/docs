---
title: "Week 3: AI UX Behavior & Patterns"
description: "Understand how users interact with AI and apply proven design patterns"
---

# Week 3: AI UX Behavior & Patterns

## Why This Week Matters for Designers

AI creates unique user behaviors and interaction patterns that don't exist in traditional software. This week helps you understand these AI-specific behaviors and apply proven design patterns to create better AI experiences.

**Designer Lens:** We'll study AI user behavior like you study any user behavior - through observation, patterns, and design principles.

## Weekly Overview

**Theme:** AI UX Behavior & Patterns  
**Time Investment:** 4 sessions × 30 minutes = 2 hours  
**Key Outcome:** You'll understand AI-specific user behaviors and know how to design for them effectively.

## Sessions

### Session 9: AI User Behavior Patterns (30 min)

**What You'll Learn:**
- How users actually interact with AI features
- Common AI user behavior patterns
- Designing for AI-specific user needs

**Materials:**
- [AI UX Behavior](/modules/ai-ux-behavior/index)

**Activity:** Observe and document AI user behavior

**Deliverable:** `week03-session09-ai-behavior-notes.md` - Your AI behavior observations

<Tip>
AI users often have different expectations and behaviors than traditional software users. Pay attention to how they approach AI features.
</Tip>

### Session 10: Design Patterns for AI (30 min)

**What You'll Learn:**
- Proven AI UX design patterns
- Common AI UX pitfalls to avoid
- Applying patterns to your own designs

**Materials:**
- [Design Patterns](/modules/design-patterns/index)

**Activity:** Audit existing AI feature for design patterns

**Deliverable:** `week03-session10-pattern-audit.md` - Your pattern audit findings

<Info>
Design patterns for AI are like design patterns for any interface - they're proven solutions to common problems. Learn them to avoid reinventing the wheel.
</Info>

### Session 11: Streaming UX & Real-time Feedback (30 min)

**What You'll Learn:**
- Designing for streaming AI responses
- Creating engaging real-time experiences
- Managing user expectations during generation

**Materials:**
- [Streaming UX](/modules/streaming-ux/index)

**Activity:** Sketch streaming UX for text generation

**Deliverable:** `week03-session11-streaming-design.md` - Your streaming UX designs

<Warning>
Streaming AI responses can feel magical or frustrating depending on how you design them. Focus on managing user expectations and providing clear feedback.
</Warning>

### Session 12: Multimodal AI Experiences (30 min)

**What You'll Learn:**
- Designing for text, image, and voice AI
- Creating cohesive multimodal flows
- Balancing different input/output modalities

**Materials:**
- [Multimodality](/modules/multimodality/index)

**Activity:** Design multimodal AI feature concept

**Deliverable:** `week03-session12-multimodal-concept.md` - Your multimodal design concept

<Check>
By the end of this week, you should understand AI-specific user behaviors and know how to apply proven design patterns to create better AI experiences.
</Check>

## Mini-Activities Between Sessions

**Between Sessions 9-10:** Use an AI feature and pay attention to your own behavior. What feels natural? What feels awkward?

**Between Sessions 10-11:** Look for streaming AI features in products you use. How do they handle the real-time experience?

**Between Sessions 11-12:** Sketch a quick concept for an AI feature that uses multiple modalities (text + image, voice + text, etc.).

## Weekly Deliverables

1. **AI Behavior Observations** - Your notes on how users interact with AI
2. **Pattern Audit Findings** - Analysis of existing AI features using design patterns
3. **Streaming UX Designs** - Sketches for real-time AI experiences
4. **Multimodal Design Concept** - Your concept for a multimodal AI feature

## Reflection Questions

- What AI user behaviors surprised you the most?
- Which design patterns felt most relevant to your work?
- How do you think AI will change user expectations in your product area?

## Next Week Preview

Week 4 focuses on **Advanced Prompting Techniques** - you'll learn sophisticated prompting methods that can create more intelligent and helpful AI experiences.

---

*Remember: AI users are still users. Apply your existing UX knowledge while learning AI-specific patterns.*


> **Note:** The following article is reproduced verbatim from
> AI Design Roundtable, *Google* (2025):
> [AI and Design: Putting People First](https://design.google/library/ai-design-roundtable-discussion)
> for internal educational use only (non-profit).

# AI and Design: Putting People First

Today’s product designers face a question their predecessors—or even their younger selves—never had to ponder: Will artificial intelligence solve this problem in a unique way? More and more, the answer is yes, with the caveat that AI isn’t a universal solution but something that in the right instance can improve an experience, by offering people new kinds of predictive information, personalized services, or even a deeper understanding of their own needs. For designers, this technology glimmers with opportunity while raising a whole host of new questions: Is AI a material, a tool, or both? How can we become AI-fluent, to ensure that algorithmic decision-making translates into a meaningful experience for everyone?

New guidance may help pave the way: PAIR’s [People + AI Guidebook](https://goo.gl/8H13f6) and [Material Design patterns for the ML Kit API](https://goo.gl/YWVpi3) each offer tactics and advice for creating products with AI. “We’re setting up the scaffolding so our users can understand this new technology,” says Material Design creative director Rachel Been. Yet building that framework requires a thoughtful, nuanced approach that’s deeply rooted in human needs. We sat down with Been, Öznur Özkurt, a design manager at DeepMind Health, and Jess Holbrook, a PAIR lead and one of the creators of the [People + AI Guidebook](https://goo.gl/8H13f6), to better understand how designers can harness and humanize AI’s vast potential.


> **Note:** The following article is reproduced verbatim from
> New Interaction Design Paradigm, *Google* (2025):
> [A New Interaction Language](https://design.google/library/a-new-interaction-design-paradigm)
> for internal educational use only (non-profit).

# A New Interaction Language

People have always had to learn new behaviors in order to operate technology. Basic computer functions like dragging and dropping, for example, or mouse and pointer interaction didn’t just come naturally. Even common gestures like touching, swiping, and pinching require re-mastering and recontextualization amid a landscape of smartphones and tablets. But as technology becomes ever more present in our lives, it’s fair to start asking technology to take a few more cues from us. This idea is central to the work of [Advanced Technology & Projects](https://atap.google.com/) (ATAP), a multidisciplinary team at Google where we’re creating a whole new interaction paradigm based on the nuances of human movement—and the promise of a miniature radar chip called Soli.


> **Note:** The following article is reproduced verbatim from
> Why Google Needs UX Engineers, *Google* (2025):
> [Why Google Needs UXEs](https://design.google/library/why-google-needs-ux-engineers)
> for internal educational use only (non-profit).

# Why Google Needs UXEs

User experience engineers, or UXEs, occupy an ever-evolving niche at Google. As creative all-rounders, they bring a balance of design savvy and technical design expertise to their roles; as thoughtful problem solvers, they apply their unique crossover skill-sets to projects across all stages of development, from intent to implementation. Prototyping is one of their superpowers. They have a knack for getting things done. We spoke with nine UXEs about their versatility as tinkerers, makers, dreamers, and builders, and why their work is so valuable.


> **Note:** The following article is reproduced verbatim from
> People + AI Research, *Google* (2025):
> [People + AI Research](https://design.google/library/people-ai-research)
> for internal educational use only (non-profit).

# People + AI Research

# People + AI Research

Get practical insights from Google’s People + AI Research (PAIR) team on how to take a multidisciplinary and human-centered approach to designing with machine learning and AI. Inside, find articles and video on how ML is changing the way we build experiences and interact with the world.


> **Note:** The following article is reproduced verbatim from
> UX Design System Dance, *Google* (2025):
> [UX Design as Dance Theater](https://design.google/library/ux-design-system-dance)
> for internal educational use only (non-profit).

# UX Design as Dance Theater

Euphrates Dahout is a Google UX Designer and the architect of the world’s most popular Figma library, the [M3 Design Kit](https://www.figma.com/community/file/1035203688168086460). Here, she shares how her love of a ’90s music video — and background in dance — has shaped the way she approaches design systems and user experience.

Have you ever seen the music video for Daft Punk’s “[Around the World](https://youtu.be/K0HSD_i2DvA)” from 1997? If not, take a few minutes to watch it. It features a captivating spectacle of synchronized swimmers, dancing mummies, and writhing skeletons — all set in a surrealist dreamscape backlit by glowing lights. Each group dances to its own beat, until the end when they come together to perform in unison.


> **Note:** The following article is reproduced verbatim from
> AI Sparkle Icon Research, *Google* (2025):
> [All That Sparkles Is AI](https://design.google/library/ai-sparkle-icon-research-pozos-schmidt)
> for internal educational use only (non-profit).

# All That Sparkles Is AI

By Rose Pozos and Lennard Schmidt


> **Note:** The following article is reproduced verbatim from
> Figma Comments Material UX, *Google* (2025):
> [Always Read the Comments](https://design.google/library/figma-comments-material-ux-euphrates-dahout)
> for internal educational use only (non-profit).

# Always Read the Comments

It’s an internet truism that if you want to maintain your sanity, you should never read the comments.

More than [one in four Americans have had their day ruined by a mean online comment](https://today.yougov.com/society/articles/19047-26-americans-say-negative-internet-comment-has-rui), and many influencers and brands are shutting off comments entirely. However, research suggests that's not the best approach. [A study from the Harvard Business Review](https://hbr.org/2024/08/research-what-happens-when-influencers-turn-off-comments) found that turning off comments can actually make people see influencers as less likable and sincere — even more so than if they just left the negative comments up.

As a UX Designer and the manager of the [Material 3 Design Kit](https://www.figma.com/community/file/1035203688168086460) — a Figma library with 3.5 million users and counting — I’ve had to learn the hard way [not to take negative feedback personally](https://uxdesign.cc/dont-take-design-critique-as-an-insult-6cf187ca6308). Today, I’ve fully embraced comments. I believe that reading and considering this feedback is an essential part of making a valuable design resource. Whether positive or negative, user feedback helps me and the Material team get people what they need.

Read on for the most helpful comments I’ve received on our Figma library, and what I learned along the way.
