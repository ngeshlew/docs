---
title: "Week 7: Safety, Security & Trust"
description: "Design AI experiences that protect users and build trust"
---

# Week 7: Safety, Security & Trust

## Why This Week Matters for Designers

AI introduces new risks and trust challenges that designers must address. This week teaches you how to design AI experiences that protect users, build trust, and handle the ethical implications of AI systems.

**Designer Lens:** Safety and trust are UX concerns, not just technical ones. You have a responsibility to design AI experiences that protect and respect your users.

## Weekly Overview

**Theme:** Safety, Security & Trust  
**Time Investment:** 4 sessions Ã— 30 minutes = 2 hours  
**Key Outcome:** You'll be able to design AI features that prioritize user safety and build trust.

## Sessions

### Session 25: AI Safety & User Protection (30 min)

**What You'll Learn:**
- Common AI safety risks and how to design around them
- Protecting users from AI-generated content
- Designing safety features into AI experiences

**Materials:**
- [Safety & Security](/modules/safety-security/index)

**Activity:** Design safety features for AI product

**Deliverable:** `week07-session25-safety-features.md` - Your AI safety design

<Tip>
Think of AI safety like accessibility - it's not an afterthought, it's a fundamental part of good design.
</Tip>

### Session 26: Trust & Transparency (30 min)

**What You'll Learn:**
- Building user trust in AI systems
- Designing transparent AI experiences
- Communicating AI capabilities and limitations

**Materials:**
- [AI UX Behavior](/modules/ai-ux-behavior/index)

**Activity:** Create trust-building UX elements

**Deliverable:** `week07-session26-trust-elements.md` - Your trust-building designs

<Info>
Trust is earned through consistent, transparent behavior. Design your AI features to be predictable and honest about their capabilities.
</Info>

### Session 27: Bias & Fairness in AI UX (30 min)

**What You'll Learn:**
- Identifying AI bias in user experiences
- Designing for fairness and inclusion
- Testing AI features for bias

**Materials:**
- [Safety & Security](/modules/safety-security/index)

**Activity:** Audit AI feature for potential bias

**Deliverable:** `week07-session27-bias-audit.md` - Your bias audit findings

<Warning>
AI bias can harm users and damage your product's reputation. Always test AI features with diverse user groups and data.
</Warning>

### Session 28: Privacy & Data Protection (30 min)

**What You'll Learn:**
- Designing for user privacy in AI systems
- Creating transparent data practices
- Building privacy controls into AI features

**Materials:**
- [Safety & Security](/modules/safety-security/index)

**Activity:** Design privacy controls for AI feature

**Deliverable:** `week07-session28-privacy-controls.md` - Your privacy design

<Check>
By the end of this week, you should be able to design AI features that protect users, build trust, and handle ethical concerns appropriately.
</Check>

## Mini-Activities Between Sessions

**Between Sessions 25-26:** Look at an AI feature you use and identify potential safety risks. How could it be designed more safely?

**Between Sessions 26-27:** Practice explaining an AI feature's limitations to a user. How can you be transparent without undermining trust?

**Between Sessions 27-28:** Review your own product's privacy policy. How does it handle AI-generated content and user data?

## Weekly Deliverables

1. **AI Safety Design** - Your safety features for AI product
2. **Trust-Building Elements** - UX elements that build user trust
3. **Bias Audit Findings** - Analysis of potential AI bias in your feature
4. **Privacy Controls Design** - Privacy features for AI system

## Reflection Questions

- What AI safety concerns are most relevant to your product area?
- How can you balance AI capabilities with user protection?
- What does "trustworthy AI" mean for your users?

## Next Week Preview

Week 8 focuses on **Cost, Latency & Performance** - you'll learn how to design AI features that are both performant and cost-effective.

---

*Remember: Safety and trust aren't just nice-to-haves - they're essential for AI products that users will actually want to use.*
