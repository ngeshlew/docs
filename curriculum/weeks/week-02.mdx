---
title: "Week 2: Prompting & Structured Outputs"
description: "Learn to design effective AI interactions and handle reliability challenges"
---

# Week 2: Prompting & Structured Outputs

## Why This Week Matters for Designers

AI features are only as good as their prompts. This week teaches you how to design AI interactions that are reliable, predictable, and user-friendly. You'll learn to think like a prompt engineer while maintaining your focus on user experience.

**Designer Lens:** We'll treat prompts as design artifacts - they're the instructions that shape how AI behaves for your users.

## Weekly Overview

**Theme:** Prompting & Structured Outputs  
**Time Investment:** 4 sessions × 30 minutes = 2 hours  
**Key Outcome:** You'll be able to design AI interactions that are reliable and provide good user experiences.

## Sessions

### Session 5: Prompt Patterns & UX Design (30 min)

**What You'll Learn:**
- Basic prompt engineering principles
- How prompt design affects user experience
- Common prompt patterns and their UX implications

**Materials:**
- [Prompting Techniques Overview](/modules/prompting-techniques/index)

**Activity:** Redesign one messy prompt → product-ready prompt

**Deliverable:** `week02-session05-prompt-redesign.md` - Your improved prompt design

<Tip>
Think of prompts as user interface design. Just like you design UI elements to guide user behavior, you design prompts to guide AI behavior.
</Tip>

### Session 6: Structured Outputs & User Experience (30 min)

**What You'll Learn:**
- How to design reliable AI responses
- Using structured outputs to improve UX
- Handling errors and edge cases gracefully

**Materials:**
- [Structured Outputs](/modules/structured-outputs/index)

**Activity:** Create JSON schema for a user-facing AI feature

**Deliverable:** `week02-session06-structured-schema.md` - Your structured output schema

<Info>
Structured outputs are like form validation for AI responses. They help ensure the AI gives you exactly what you need in a predictable format.
</Info>

### Session 7: Error Handling & Fallbacks (30 min)

**What You'll Learn:**
- Designing graceful failure modes for AI
- Maintaining user trust during AI errors
- Creating fallback experiences

**Materials:**
- [AI UX Behavior](/modules/ai-ux-behavior/index)

**Activity:** Sketch error states for AI feature

**Deliverable:** `week02-session07-error-designs.md` - Your error handling designs

<Warning>
AI will make mistakes. Your job is to design experiences that handle these mistakes gracefully and maintain user trust.
</Warning>

### Session 8: Prompting Best Practices (30 min)

**What You'll Learn:**
- Advanced prompting techniques for better UX
- Optimizing prompts for user outcomes
- Testing and iterating on prompt design

**Materials:**
- [Advanced Prompting](/modules/prompting-advanced/index)

**Activity:** Create prompt evaluation rubric

**Deliverable:** `week02-session08-prompt-rubric.md` - Your prompt evaluation framework

<Check>
By the end of this week, you should be able to design AI interactions that are reliable, predictable, and provide good user experiences.
</Check>

## Mini-Activities Between Sessions

**Between Sessions 5-6:** Test a prompt with different inputs and observe how the AI responds. Note what makes responses more or less reliable.

**Between Sessions 6-7:** Look at an existing AI feature and identify potential failure points. How could you design better error handling?

**Between Sessions 7-8:** Practice writing prompts for a simple task. Focus on clarity and reliability.

## Weekly Deliverables

1. **Improved Prompt Design** - Your redesigned prompt with UX improvements
2. **Structured Output Schema** - JSON schema for reliable AI responses
3. **Error Handling Designs** - Sketches of graceful failure modes
4. **Prompt Evaluation Rubric** - Framework for testing prompt quality

## Reflection Questions

- What makes a prompt "good" from a user experience perspective?
- How do you balance AI flexibility with reliability in your designs?
- What error handling patterns felt most important for your users?

## Next Week Preview

Week 3 focuses on **AI UX Behavior & Patterns** - you'll learn how users actually interact with AI and how to design for AI-specific behaviors.

---

*Remember: Good prompt design is good UX design. You're designing the conversation between your users and the AI.*


> **Note:** The following article is reproduced verbatim from
> Control and Simplicity, *Google* (2025):
> [Control and Simplicity in the Age of AI](https://design.google/library/control-and-simplicity)
> for internal educational use only (non-profit).

# Control and Simplicity in the Age of AI

“A designer knows he has achieved perfection not when there is nothing left to add, but when there is nothing left to take away.”— Antoine de Saint-Exupéry


> **Note:** The following article is reproduced verbatim from
> Natural Language Failures, *Microsoft* (2025):
> [[Planning for Natural Language Failures with the AI Playbook](https://www.microsoft.com/en-us/research/publication/planning-for-natural-language-failures-with-the-ai-playbook/)](https://www.microsoft.com/en-us/research/publication/planning-for-natural-language-failures-with-the-ai-playbook/)
> for internal educational use only (non-profit).

# [Planning for Natural Language Failures with the AI Playbook](https://www.microsoft.com/en-us/research/publication/planning-for-natural-language-failures-with-the-ai-playbook/)

# [Planning for Natural Language Failures with the AI Playbook](https://www.microsoft.com/en-us/research/publication/planning-for-natural-language-failures-with-the-ai-playbook/)

### [Launch the Playbook (opens in new tab)](https://microsoft.github.io/HAXPlaybook/)

## Events

## Groups

## Projects

## Research Areas

## [Create human-centered AI with the Human-AI eXperience (HAX) Toolkit webinar](https://www.microsoft.com/en-us/research/video/create-human-centered-ai-with-the-human-ai-experience-hax-toolkit-webinar/)

2021 CHI Conference on Human Factors in Computing Systems

	 | May 2021

Prototyping AI user experiences is challenging due in part to probabilistic AI models making it difficult to anticipate, test, and mitigate AI failures before deployment. In this work, we set out to support practitioners with early AI prototyping, with a focus on natural language (NL)-based technologies. Our interviews with 12 NL practitioners from a large technology company revealed that, in addition to challenges prototyping AI, prototyping was often not happening at all or focused only on idealized scenarios due to a lack of tools and tight timelines. These findings informed our design of the AI Playbook, an interactive and low-cost tool we developed to encourage proactive and systematic consideration of AI errors before deployment. Our evaluation of the AI Playbook demonstrates its potential to 1) encourage product teams to prioritize both ideal and failure scenarios, 2) standardize the articulation of AI failures from a user experience perspective, and 3) act as a boundary object between user experience designers, data scientists, and engineers.

Visit our [GitHub page (opens in new tab)](https://github.com/microsoft/HAXPlaybook) to learn more.

The tech industry is being called upon to develop and deploy AI technologies more responsibly. Yet many organizations that create AI technologies report being unprepared to address AI risks and failures.

To meet these challenges, Microsoft is striving to take a human-centered approach to AI, designing and building technologies that benefit people and society while also mitigating potential harms. This includes understanding human needs and using that insight to drive development decisions from beginning to end.

To assist AI practitioners in building human-centered AI, we are introducing the Human-AI eXperience (HAX) Toolkit, launching on July 19. This suite of tools spans the end-to-end product development lifecycle, providing support where AI practitioners have requested it.

In this webinar, join [[Saleema Amershi](https://www.microsoft.com/en-us/research/people/samershi/)](https://www.microsoft.com/en-us/research/people/samershi/), Senior Principal Research Manager, and [Mihaela Vorvoreanu](https://www.microsoft.com/en-us/research/people/mivorvor/), Aether Director of UX Research and RAI education, to learn how and when to use each tool in the HAX Toolkit to create human-centered AI.

Together, you’ll explore:

Resource list:

*This on-demand webinar features a previously recorded Q&A session and open captioning.

Explore more Microsoft Research webinars: [https://aka.ms/msrwebinars (opens in new tab)](https://aka.ms/msrwebinars)

- Matthew K. Hong
						,
- [Adam Fourney](https://www.microsoft.com/en-us/research/people/adamfo/)

						,
- Derek DeBellis
						,
- [[Saleema Amershi](https://www.microsoft.com/en-us/research/people/samershi/)](https://www.microsoft.com/en-us/research/people/samershi/)

- [Microsoft at CHI 2021](https://www.microsoft.com/en-us/research/event/chi-2021/)

- [HAX Team](https://www.microsoft.com/en-us/research/group/hax-team/)

- [The HAX Toolkit Project](https://www.microsoft.com/en-us/research/project/hax-toolkit/)

- [Artificial intelligence](https://www.microsoft.com/en-us/research/research-area/artificial-intelligence/)
- [Human-computer interaction](https://www.microsoft.com/en-us/research/research-area/human-computer-interaction/)

- [Guidelines for Human-AI Interaction](https://www.microsoft.com/en-us/research/publication/guidelines-for-human-ai-interaction/) – best practices for how AI systems should behave during user interactions that synthesize more than 20 years of guidance on this topic
- The HAX Workbook – a tool to guide teams through planning and implementing human-AI interaction best practices
- The HAX Design Patterns – a set of flexible solutions to recurring human-AI interaction problems
- The HAX Playbook – an interactive tool for generating scenarios to test based on likely human-AI interaction failures

- [The Human-AI eXperience (HAX) Toolkit (opens in new tab)](https://aka.ms/haxtoolkit)
- [The Human-AI eXperience (HAX) Team](https://www.microsoft.com/en-us/research/project/hax-toolkit/) (project page)
- [Guidelines for Human-AI Interaction](https://www.microsoft.com/en-us/research/publication/guidelines-for-human-ai-interaction/) (publication)
- [Planning for Natural Language Failures with the AI Playbook](https://www.microsoft.com/en-us/research/publication/planning-for-natural-language-failures-with-the-ai-playbook/) (publication)
- [Mihaela Vorvoreanu](https://www.microsoft.com/en-us/research/people/mivorvor/) (researcher profile)
- [[Saleema Amershi](https://www.microsoft.com/en-us/research/people/samershi/)](https://www.microsoft.com/en-us/research/people/samershi/) (researcher profile)
