---
title: "Automatic Reasoning"
description: "Learn how to implement automatic reasoning systems that can solve complex problems through systematic logical analysis and step-by-step deduction"
slug: "modules-prompting-techniques-automatic-reasoning"
updatedAt: "2025-08-19"
tags: [prompting-technique, automatic-reasoning, logical-reasoning, problem-solving]
---

# Automatic Reasoning

<Callout type="info">
  **Learning Objective**: Master automatic reasoning techniques that enable AI systems to solve complex problems through systematic logical analysis and step-by-step deduction.
</Callout>

## Overview

Automatic Reasoning is an advanced prompting technique that enables AI systems to solve complex problems by breaking them down into logical steps, applying systematic reasoning patterns, and arriving at conclusions through structured analysis rather than pattern matching.

<CardGroup cols={2}>
  <Card title="Systematic Analysis" icon="search">
    Breaks complex problems into logical, manageable steps for systematic solution.
  </Card>
  <Card title="Logical Deduction" icon="git-branch">
    Uses formal reasoning patterns to arrive at conclusions through logical inference.
  </Card>
</CardGroup>

## What is Automatic Reasoning?

Automatic Reasoning is a technique where AI systems:

- **Decompose Problems**: Break complex problems into smaller, manageable components
- **Apply Logical Rules**: Use formal reasoning patterns and logical inference
- **Systematic Analysis**: Follow structured approaches to problem-solving
- **Verifiable Conclusions**: Arrive at conclusions that can be traced and verified

<Callout type="warning">
  **Key Insight**: Automatic reasoning goes beyond pattern matching to implement genuine logical thinking processes that can handle novel, complex problems.
</Callout>

## Key Concepts

### 1. **Reasoning Patterns**

<Card title="Common Reasoning Patterns">
  <Table>
    <TableHead>
      <TableRow>
        <TableHeader>Pattern</TableHeader>
        <TableHeader>Description</TableHeader>
        <TableHeader>Example</TableHeader>
      </TableRow>
    </TableHead>
    <TableBody>
      <TableRow>
        <TableCell><strong>Deductive Reasoning</strong></TableCell>
        <TableCell>Draw specific conclusions from general principles</TableCell>
        <TableCell>All humans are mortal. Socrates is human. Therefore, Socrates is mortal.</TableCell>
      </TableRow>
      <TableRow>
        <TableCell><strong>Inductive Reasoning</strong></TableCell>
        <TableCell>Draw general conclusions from specific observations</TableCell>
        <TableCell>Every swan I've seen is white. Therefore, all swans are white.</TableCell>
      </TableRow>
      <TableRow>
        <TableCell><strong>Abductive Reasoning</strong></TableCell>
        <TableCell>Find the best explanation for observations</TableCell>
        <TableCell>The grass is wet. The best explanation is that it rained.</TableCell>
      </TableRow>
      <TableRow>
        <TableCell><strong>Analogical Reasoning</strong></TableCell>
        <TableCell>Solve problems by analogy to similar situations</TableCell>
        <TableCell>This problem is like a puzzle. I'll solve it step by step.</TableCell>
      </TableRow>
    </TableBody>
  </Table>
</Card>

### 2. **Problem Decomposition**

<Card title="Systematic Problem Breakdown">
  <ol>
    <li><strong>Problem Analysis:</strong> Understand the problem structure and requirements</li>
    <li><strong>Subproblem Identification:</strong> Break the problem into smaller, solvable parts</li>
    <li><strong>Solution Strategy:</strong> Determine the best approach for each subproblem</li>
    <li><strong>Integration:</strong> Combine solutions to form the complete answer</li>
    <li><strong>Verification:</strong> Check that the solution is correct and complete</li>
  </ol>
</Card>

### 3. **Logical Frameworks**

<Card title="Reasoning Frameworks">
  <h4>Mathematical Reasoning:</h4>
  <ul>
    <li>Algebraic manipulation and equation solving</li>
    <li>Geometric proofs and spatial reasoning</li>
    <li>Statistical analysis and probability</li>
    <li>Mathematical induction and recursion</li>
  </ul>
  
  <h4>Scientific Reasoning:</h4>
  <ul>
    <li>Hypothesis formation and testing</li>
    <li>Experimental design and analysis</li>
    <li>Causal inference and correlation</li>
    <li>Model building and validation</li>
  </ul>
</Card>

## Implementation

### 1. **Basic Automatic Reasoning**

<CodeGroup>
  <CodeGroupItem title="Python" active>
```python
class AutomaticReasoner:
    def __init__(self):
        self.reasoning_patterns = {
            'deductive': self.deductive_reasoning,
            'inductive': self.inductive_reasoning,
            'abductive': self.abductive_reasoning,
            'analogical': self.analogical_reasoning
        }
    
    def solve_problem(self, problem_description: str) -> dict:
        """Main problem-solving method"""
        
        # Step 1: Analyze the problem
        problem_analysis = self.analyze_problem(problem_description)
        
        # Step 2: Identify reasoning approach
        reasoning_type = self.identify_reasoning_type(problem_analysis)
        
        # Step 3: Apply reasoning
        solution = self.reasoning_patterns[reasoning_type](problem_analysis)
        
        # Step 4: Verify solution
        verification = self.verify_solution(solution, problem_analysis)
        
        return {
            'problem': problem_description,
            'analysis': problem_analysis,
            'reasoning_type': reasoning_type,
            'solution': solution,
            'verification': verification
        }
    
    def analyze_problem(self, problem: str) -> dict:
        """Analyze problem structure and requirements"""
        return {
            'type': self.classify_problem_type(problem),
            'components': self.extract_components(problem),
            'constraints': self.identify_constraints(problem),
            'goals': self.identify_goals(problem)
        }
    
    def identify_reasoning_type(self, analysis: dict) -> str:
        """Determine the best reasoning approach"""
        problem_type = analysis['type']
        
        if problem_type in ['mathematical', 'logical']:
            return 'deductive'
        elif problem_type in ['pattern_recognition', 'classification']:
            return 'inductive'
        elif problem_type in ['explanation', 'diagnosis']:
            return 'abductive'
        else:
            return 'analogical'
    
    def deductive_reasoning(self, analysis: dict) -> dict:
        """Apply deductive reasoning"""
        # Start with general principles
        principles = self.extract_principles(analysis)
        
        # Apply logical rules
        intermediate_steps = []
        for principle in principles:
            step = self.apply_principle(principle, analysis)
            intermediate_steps.append(step)
        
        # Draw conclusion
        conclusion = self.draw_conclusion(intermediate_steps)
        
        return {
            'method': 'deductive',
            'principles': principles,
            'steps': intermediate_steps,
            'conclusion': conclusion
        }
    
    def inductive_reasoning(self, analysis: dict) -> dict:
        """Apply inductive reasoning"""
        # Collect observations
        observations = self.extract_observations(analysis)
        
        # Identify patterns
        patterns = self.identify_patterns(observations)
        
        # Form generalization
        generalization = self.form_generalization(patterns)
        
        return {
            'method': 'inductive',
            'observations': observations,
            'patterns': patterns,
            'generalization': generalization
        }
    
    def abductive_reasoning(self, analysis: dict) -> dict:
        """Apply abductive reasoning"""
        # Identify observations
        observations = analysis['components']
        
        # Generate possible explanations
        explanations = self.generate_explanations(observations)
        
        # Select best explanation
        best_explanation = self.select_best_explanation(explanations)
        
        return {
            'method': 'abductive',
            'observations': observations,
            'explanations': explanations,
            'best_explanation': best_explanation
        }
    
    def analogical_reasoning(self, analysis: dict) -> dict:
        """Apply analogical reasoning"""
        # Find similar problems
        similar_problems = self.find_similar_problems(analysis)
        
        # Extract solution patterns
        solution_patterns = self.extract_solution_patterns(similar_problems)
        
        # Adapt to current problem
        adapted_solution = self.adapt_solution(solution_patterns, analysis)
        
        return {
            'method': 'analogical',
            'similar_problems': similar_problems,
            'solution_patterns': solution_patterns,
            'adapted_solution': adapted_solution
        }
    
    def verify_solution(self, solution: dict, analysis: dict) -> dict:
        """Verify the solution is correct and complete"""
        checks = {
            'completeness': self.check_completeness(solution, analysis),
            'correctness': self.check_correctness(solution, analysis),
            'consistency': self.check_consistency(solution),
            'feasibility': self.check_feasibility(solution)
        }
        
        return {
            'checks': checks,
            'overall_valid': all(checks.values())
        }

# Example usage
reasoner = AutomaticReasoner()

problem = "If all students in the class passed the exam, and John is a student in the class, did John pass the exam?"

result = reasoner.solve_problem(problem)
print(f"Reasoning Type: {result['reasoning_type']}")
print(f"Solution: {result['solution']['conclusion']}")
```
  </CodeGroupItem>
  
  <CodeGroupItem title="JavaScript">
```javascript
class AutomaticReasoner {
    constructor() {
        this.reasoningPatterns = {
            deductive: this.deductiveReasoning.bind(this),
            inductive: this.inductiveReasoning.bind(this),
            abductive: this.abductiveReasoning.bind(this),
            analogical: this.analogicalReasoning.bind(this)
        };
    }
    
    solveProblem(problemDescription) {
        // Step 1: Analyze the problem
        const problemAnalysis = this.analyzeProblem(problemDescription);
        
        // Step 2: Identify reasoning approach
        const reasoningType = this.identifyReasoningType(problemAnalysis);
        
        // Step 3: Apply reasoning
        const solution = this.reasoningPatterns[reasoningType](problemAnalysis);
        
        // Step 4: Verify solution
        const verification = this.verifySolution(solution, problemAnalysis);
        
        return {
            problem: problemDescription,
            analysis: problemAnalysis,
            reasoningType: reasoningType,
            solution: solution,
            verification: verification
        };
    }
    
    analyzeProblem(problem) {
        return {
            type: this.classifyProblemType(problem),
            components: this.extractComponents(problem),
            constraints: this.identifyConstraints(problem),
            goals: this.identifyGoals(problem)
        };
    }
    
    identifyReasoningType(analysis) {
        const problemType = analysis.type;
        
        if (['mathematical', 'logical'].includes(problemType)) {
            return 'deductive';
        } else if (['pattern_recognition', 'classification'].includes(problemType)) {
            return 'inductive';
        } else if (['explanation', 'diagnosis'].includes(problemType)) {
            return 'abductive';
        } else {
            return 'analogical';
        }
    }
    
    deductiveReasoning(analysis) {
        // Start with general principles
        const principles = this.extractPrinciples(analysis);
        
        // Apply logical rules
        const intermediateSteps = principles.map(principle => 
            this.applyPrinciple(principle, analysis)
        );
        
        // Draw conclusion
        const conclusion = this.drawConclusion(intermediateSteps);
        
        return {
            method: 'deductive',
            principles: principles,
            steps: intermediateSteps,
            conclusion: conclusion
        };
    }
    
    inductiveReasoning(analysis) {
        // Collect observations
        const observations = this.extractObservations(analysis);
        
        // Identify patterns
        const patterns = this.identifyPatterns(observations);
        
        // Form generalization
        const generalization = this.formGeneralization(patterns);
        
        return {
            method: 'inductive',
            observations: observations,
            patterns: patterns,
            generalization: generalization
        };
    }
    
    abductiveReasoning(analysis) {
        // Identify observations
        const observations = analysis.components;
        
        // Generate possible explanations
        const explanations = this.generateExplanations(observations);
        
        // Select best explanation
        const bestExplanation = this.selectBestExplanation(explanations);
        
        return {
            method: 'abductive',
            observations: observations,
            explanations: explanations,
            bestExplanation: bestExplanation
        };
    }
    
    analogicalReasoning(analysis) {
        // Find similar problems
        const similarProblems = this.findSimilarProblems(analysis);
        
        // Extract solution patterns
        const solutionPatterns = this.extractSolutionPatterns(similarProblems);
        
        // Adapt to current problem
        const adaptedSolution = this.adaptSolution(solutionPatterns, analysis);
        
        return {
            method: 'analogical',
            similarProblems: similarProblems,
            solutionPatterns: solutionPatterns,
            adaptedSolution: adaptedSolution
        };
    }
    
    verifySolution(solution, analysis) {
        const checks = {
            completeness: this.checkCompleteness(solution, analysis),
            correctness: this.checkCorrectness(solution, analysis),
            consistency: this.checkConsistency(solution),
            feasibility: this.checkFeasibility(solution)
        };
        
        return {
            checks: checks,
            overallValid: Object.values(checks).every(check => check)
        };
    }
}

// Example usage
const reasoner = new AutomaticReasoner();

const problem = "If all students in the class passed the exam, and John is a student in the class, did John pass the exam?";

const result = reasoner.solveProblem(problem);
console.log(`Reasoning Type: ${result.reasoningType}`);
console.log(`Solution: ${result.solution.conclusion}`);
```
  </CodeGroupItem>
</CodeGroup>

### 2. **LangChain Integration**

<Card title="LangChain Automatic Reasoning">
  <CodeGroup>
    <CodeGroupItem title="LangChain Implementation" active>
```python
from langchain.prompts import PromptTemplate
from langchain.chains import LLMChain
from langchain.llms import OpenAI
from langchain.output_parsers import PydanticOutputParser
from pydantic import BaseModel, Field
from typing import List, Dict, Any
import json

class ReasoningStep(BaseModel):
    step_number: int = Field(description="The step number in the reasoning process")
    reasoning_type: str = Field(description="Type of reasoning used (deductive, inductive, etc.)")
    premise: str = Field(description="The premise or observation for this step")
    conclusion: str = Field(description="The conclusion drawn from this step")
    confidence: float = Field(description="Confidence level (0-1) for this step")

class AutomaticReasoningChain:
    def __init__(self, api_key: str):
        self.llm = OpenAI(api_key=api_key, temperature=0.1)
        self.parser = PydanticOutputParser(pydantic_object=ReasoningStep)
        
        # Create reasoning prompt template
        self.reasoning_prompt = PromptTemplate(
            template="""
            You are an expert in automatic reasoning. Solve the following problem using systematic logical analysis.
            
            Problem: {problem}
            
            Please break down your reasoning into clear, logical steps. For each step, identify:
            1. The type of reasoning used (deductive, inductive, abductive, or analogical)
            2. The premise or observation
            3. The conclusion drawn
            4. Your confidence level (0-1)
            
            Format your response as a JSON array of reasoning steps.
            
            {format_instructions}
            """,
            input_variables=["problem"],
            partial_variables={"format_instructions": self.parser.get_format_instructions()}
        )
        
        self.chain = LLMChain(llm=self.llm, prompt=self.reasoning_prompt)
    
    def solve_problem(self, problem: str) -> Dict[str, Any]:
        """Solve a problem using automatic reasoning"""
        
        try:
            # Generate reasoning steps
            response = self.chain.run(problem=problem)
            
            # Parse the response
            reasoning_steps = self.parser.parse(response)
            
            # Analyze the reasoning process
            analysis = self.analyze_reasoning(reasoning_steps)
            
            # Generate final conclusion
            conclusion = self.generate_conclusion(reasoning_steps, analysis)
            
            return {
                'problem': problem,
                'reasoning_steps': reasoning_steps,
                'analysis': analysis,
                'conclusion': conclusion,
                'confidence': analysis['overall_confidence']
            }
            
        except Exception as e:
            return {
                'error': str(e),
                'problem': problem
            }
    
    def analyze_reasoning(self, steps: List[ReasoningStep]) -> Dict[str, Any]:
        """Analyze the reasoning process"""
        
        reasoning_types = [step.reasoning_type for step in steps]
        confidences = [step.confidence for step in steps]
        
        return {
            'total_steps': len(steps),
            'reasoning_types_used': list(set(reasoning_types)),
            'average_confidence': sum(confidences) / len(confidences) if confidences else 0,
            'overall_confidence': min(confidences) if confidences else 0,  # Conservative estimate
            'reasoning_complexity': self.calculate_complexity(steps)
        }
    
    def calculate_complexity(self, steps: List[ReasoningStep]) -> str:
        """Calculate the complexity of the reasoning process"""
        if len(steps) <= 2:
            return "simple"
        elif len(steps) <= 5:
            return "moderate"
        else:
            return "complex"
    
    def generate_conclusion(self, steps: List[ReasoningStep], analysis: Dict[str, Any]) -> str:
        """Generate a final conclusion based on reasoning steps"""
        
        if not steps:
            return "Unable to reach a conclusion due to insufficient reasoning steps."
        
        # Use the conclusion from the last step
        final_step = steps[-1]
        
        return f"Based on {len(steps)} steps of {analysis['reasoning_types_used'][0]} reasoning, the conclusion is: {final_step.conclusion}"

# Example usage
reasoning_chain = AutomaticReasoningChain("your-api-key")

problem = """
A company has 100 employees. 60% are engineers, 30% are designers, and 10% are managers.
If 20% of engineers are senior engineers, how many senior engineers are there?
"""

result = reasoning_chain.solve_problem(problem)
print(f"Conclusion: {result['conclusion']}")
print(f"Confidence: {result['confidence']}")
print(f"Steps: {len(result['reasoning_steps'])}")
```
  </CodeGroupItem>
  </CodeGroup>
</Card>

### 3. **CrewAI Integration**

<Card title="CrewAI Multi-Agent Reasoning">
  <CodeGroup>
    <CodeGroupItem title="CrewAI Implementation" active>
```python
from crewai import Agent, Task, Crew
from langchain.tools import Tool
import json

class ReasoningCrew:
    def __init__(self):
        self.analyst_agent = None
        self.reasoner_agent = None
        self.verifier_agent = None
    
    def create_agents(self):
        """Create specialized reasoning agents"""
        
        # Problem Analyst Agent
        self.analyst_agent = Agent(
            role="Problem Analyst",
            goal="Analyze complex problems and break them down into solvable components",
            backstory="""You are an expert problem analyst with deep experience in 
            breaking down complex problems into manageable components. You excel at 
            identifying problem types, constraints, and solution approaches.""",
            verbose=True,
            allow_delegation=False
        )
        
        # Reasoning Agent
        self.reasoner_agent = Agent(
            role="Logical Reasoner",
            goal="Apply systematic reasoning to solve problems step by step",
            backstory="""You are a master of logical reasoning with expertise in 
            deductive, inductive, abductive, and analogical reasoning. You can solve 
            complex problems through systematic analysis and logical inference.""",
            verbose=True,
            allow_delegation=False
        )
        
        # Verification Agent
        self.verifier_agent = Agent(
            role="Solution Verifier",
            goal="Verify the correctness and completeness of reasoning solutions",
            backstory="""You are a meticulous verifier who ensures that reasoning 
            solutions are correct, complete, and logically sound. You catch errors 
            and identify gaps in reasoning.""",
            verbose=True,
            allow_delegation=False
        )
    
    def analyze_problem_task(self, problem: str) -> Task:
        """Create task for problem analysis"""
        return Task(
            description=f"""
            Analyze the following problem and break it down into components:
            
            Problem: {problem}
            
            Your analysis should include:
            1. Problem type classification
            2. Key components and variables
            3. Constraints and assumptions
            4. Recommended reasoning approach
            5. Potential challenges
            
            Provide a structured analysis that can guide the reasoning process.
            """,
            agent=self.analyst_agent
        )
    
    def reason_task(self, problem_analysis: str, problem: str) -> Task:
        """Create task for reasoning"""
        return Task(
            description=f"""
            Using the problem analysis provided, solve the problem through systematic reasoning:
            
            Problem: {problem}
            Analysis: {problem_analysis}
            
            Apply the appropriate reasoning method (deductive, inductive, abductive, or analogical)
            and provide a step-by-step solution with clear logical progression.
            
            For each step, explain:
            1. The reasoning type used
            2. The premise or observation
            3. The logical conclusion
            4. The confidence level
            
            Ensure your reasoning is clear, logical, and verifiable.
            """,
            agent=self.reasoner_agent
        )
    
    def verify_task(self, reasoning_solution: str, problem: str) -> Task:
        """Create task for solution verification"""
        return Task(
            description=f"""
            Verify the reasoning solution for the following problem:
            
            Problem: {problem}
            Solution: {reasoning_solution}
            
            Check for:
            1. Logical correctness
            2. Completeness of reasoning
            3. Consistency of conclusions
            4. Validity of assumptions
            5. Potential errors or gaps
            
            Provide a verification report with any issues found and recommendations for improvement.
            """,
            agent=self.verifier_agent
        )
    
    def solve_problem(self, problem: str) -> Dict[str, Any]:
        """Solve a problem using the reasoning crew"""
        
        # Create agents
        self.create_agents()
        
        # Create tasks
        analysis_task = self.analyze_problem_task(problem)
        reasoning_task = self.reason_task("", problem)  # Will be updated
        verification_task = self.verify_task("", problem)  # Will be updated
        
        # Create crew
        crew = Crew(
            agents=[self.analyst_agent, self.reasoner_agent, self.verifier_agent],
            tasks=[analysis_task, reasoning_task, verification_task],
            verbose=True
        )
        
        # Execute reasoning process
        result = crew.kickoff()
        
        return {
            'problem': problem,
            'crew_result': result,
            'agents': {
                'analyst': self.analyst_agent,
                'reasoner': self.reasoner_agent,
                'verifier': self.verifier_agent
            }
        }

# Example usage
reasoning_crew = ReasoningCrew()

problem = """
A train leaves station A at 2:00 PM traveling at 60 mph. Another train leaves station B 
at 2:30 PM traveling at 80 mph toward station A. If the stations are 200 miles apart, 
when will the trains meet?
"""

result = reasoning_crew.solve_problem(problem)
print(result['crew_result'])
```
  </CodeGroupItem>
  </CodeGroup>
</Card>

## Best Practices

### 1. **Problem Analysis**

<CardGroup cols={2}>
  <Card title="Systematic Breakdown" icon="list">
    <ul>
      <li>Identify problem components</li>
      <li>Classify problem type</li>
      <li>Extract constraints</li>
      <li>Define success criteria</li>
    </ul>
  </Card>
  <Card title="Reasoning Selection" icon="target">
    <ul>
      <li>Choose appropriate reasoning type</li>
      <li>Consider problem complexity</li>
      <li>Match reasoning to problem</li>
      <li>Plan reasoning sequence</li>
    </ul>
  </Card>
</CardGroup>

### 2. **Solution Verification**

<Card title="Verification Strategies">
  <ul>
    <li><strong>Logical Consistency:</strong> Check that conclusions follow from premises</li>
    <li><strong>Completeness:</strong> Ensure all aspects of the problem are addressed</li>
    <li><strong>Correctness:</strong> Verify that the solution is mathematically/logically correct</li>
    <li><strong>Feasibility:</strong> Confirm that the solution is practical and implementable</li>
  </ul>
</Card>

### 3. **Error Handling**

<Card title="Error Prevention">
  <ul>
    <li><strong>Assumption Validation:</strong> Verify that assumptions are reasonable</li>
    <li><strong>Step Verification:</strong> Check each reasoning step for errors</li>
    <li><strong>Alternative Approaches:</strong> Consider multiple solution methods</li>
    <li><strong>Confidence Assessment:</strong> Evaluate confidence in conclusions</li>
  </ul>
</Card>

## Real-World Applications

### 1. **Mathematical Problem Solving**

<Callout type="info">
  **Case Study**: Automatic reasoning is particularly effective for mathematical problems that require step-by-step logical analysis.
</Callout>

<Card title="Mathematical Applications">
  <ul>
    <li><strong>Algebraic Equations:</strong> Systematic solving of complex equations</li>
    <li><strong>Geometric Proofs:</strong> Logical deduction in geometry</li>
    <li><strong>Calculus Problems:</strong> Step-by-step differentiation and integration</li>
    <li><strong>Statistics:</strong> Probabilistic reasoning and inference</li>
  </ul>
</Card>

### 2. **Scientific Research**

<Card title="Scientific Reasoning">
  <ul>
    <li><strong>Hypothesis Testing:</strong> Systematic testing of scientific hypotheses</li>
    <li><strong>Data Analysis:</strong> Logical interpretation of experimental results</li>
    <li><strong>Model Building:</strong> Constructing and validating scientific models</li>
    <li><strong>Causal Inference:</strong> Determining cause-and-effect relationships</li>
  </ul>
</Card>

## Related Techniques

<CardGroup cols={3}>
  <Card title="Chain-of-Thought" icon="git-branch" href="./chain-of-thought">
    Step-by-step reasoning prompts
  </Card>
  <Card title="Tree of Thoughts" icon="git-merge" href="./tree-of-thoughts">
    Exploring multiple reasoning paths
  </Card>
  <Card title="Self-Consistency" icon="repeat" href="./self-consistency">
    Multiple reasoning paths for validation
  </Card>
  <Card title="Program-Aided Language Models" icon="code" href="./program-aided-language-models">
    Using code to enhance reasoning
  </Card>
  <Card title="Reflexion" icon="refresh-cw" href="./reflexion">
    Self-reflection and improvement
  </Card>
  <Card title="Graph Prompting" icon="network" href="./graph-prompting">
    Structured reasoning with graphs
  </Card>
</CardGroup>

## Sources

<Card title="Reference Materials">
  <ul>
    <li><strong>CrewAI Documentation:</strong> <a href="https://docs.crewai.com/en/introduction">https://docs.crewai.com/en/introduction</a></li>
    <li><strong>AI Design Guide:</strong> <a href="https://aidesign.guide/">https://aidesign.guide/</a></li>
    <li><strong>LangChain Conceptual Guide:</strong> <a href="https://python.langchain.com/docs/get_started/concepts">https://python.langchain.com/docs/get_started/concepts</a></li>
    <li><strong>NLP and LLMs 2024:</strong> <a href="https://nlp2024.jeju.ai/">https://nlp2024.jeju.ai/</a></li>
    <li><strong>Prompt Engineering Guide:</strong> <a href="https://www.promptingguide.ai/">https://www.promptingguide.ai/</a></li>
    <li><strong>Anthropic Tutorial:</strong> <a href="https://www.anthropic.com/">https://www.anthropic.com/</a></li>
  </ul>
</Card>
