---
title: "AI Foundations"
description: "Master the fundamental concepts of AI, machine learning, and large language models that form the basis of modern AI applications"
slug: "modules-foundations"
updatedAt: "2025-08-19"
tags: [module, foundations, ai, machine-learning, llms, claude, anthropic]
---

# AI Foundations

<Callout type="info">
  **Learning Objective**: Understand the fundamental concepts of AI, machine learning, and large language models that form the basis of modern AI applications and inform design decisions.
</Callout>

## Overview

AI foundations provide the theoretical and practical understanding needed to build effective AI-powered products. This module covers the core concepts, architectures, and principles that drive modern AI systems, with a focus on how these fundamentals influence design and user experience.

<CardGroup cols={2}>
  <Card title="Core Concepts" icon="brain">
    Understanding the fundamental principles of AI and machine learning enables better design decisions and more effective collaboration with engineering teams.
  </Card>
  <Card title="Practical Applications" icon="zap">
    These foundations directly inform how we design AI-powered interfaces, interactions, and user experiences.
  </Card>
</CardGroup>

## Anthropic Claude: Enterprise AI Foundation

<Callout type="info">
  **Claude Overview**: Claude is a family of highly performant and intelligent AI models built by Anthropic, designed to be the most trustworthy and reliable AI available for enterprise applications.
</Callout>

### Claude's Core Capabilities

<CardGroup cols={3}>
  <Card title="Text and Code Generation" icon="file-text">
    <ul>
      <li>Brand voice adherence for customer experiences</li>
      <li>Production-level code generation and debugging</li>
      <li>Automatic translation between languages</li>
      <li>Complex financial forecasting</li>
      <li>High-quality technical analysis</li>
    </ul>
  </Card>
  <Card title="Vision Processing" icon="eye">
    <ul>
      <li>Chart and graph analysis</li>
      <li>Code generation from images</li>
      <li>Image description for accessibility</li>
      <li>Visual data extraction</li>
      <li>Document processing</li>
    </ul>
  </Card>
  <Card title="Tool Use" icon="wrench">
    <ul>
      <li>External tool integration</li>
      <li>Structured output generation</li>
      <li>API interaction capabilities</li>
      <li>Function calling support</li>
      <li>Workflow automation</li>
    </ul>
  </Card>
</CardGroup>

### Enterprise Considerations

<Table>
  <TableHead>
    <TableRow>
      <TableHeader>Feature</TableHeader>
      <TableHeader>Description</TableHeader>
      <TableHeader>Enterprise Benefit</TableHeader>
    </TableRow>
  </TableHead>
  <TableBody>
    <TableRow>
      <TableCell><strong>Security</strong></TableCell>
      <TableCell>Enterprise-grade security, SOC II Type 2 certified, HIPAA compliance options</TableCell>
      <TableCell>Trust and compliance for sensitive data</TableCell>
    </TableRow>
    <TableRow>
      <TableCell><strong>Trustworthiness</strong></TableCell>
      <TableCell>Resistant to jailbreaks, copyright indemnity protections</TableCell>
      <TableCell>Safe deployment in high-trust industries</TableCell>
    </TableRow>
    <TableRow>
      <TableCell><strong>Capability</strong></TableCell>
      <TableCell>200K token context window, tool use, multimodal input</TableCell>
      <TableCell>Handles complex, real-world applications</TableCell>
    </TableRow>
    <TableRow>
      <TableCell><strong>Reliability</strong></TableCell>
      <TableCell>Very low hallucination rates, accurate over long documents</TableCell>
      <TableCell>Consistent, dependable performance</TableCell>
    </TableRow>
    <TableRow>
      <TableCell><strong>Global</strong></TableCell>
      <TableCell>Fluency in English and non-English languages</TableCell>
      <TableCell>International deployment capabilities</TableCell>
    </TableRow>
    <TableRow>
      <TableCell><strong>Cost Conscious</strong></TableCell>
      <TableCell>Family of models balancing cost, performance, and intelligence</TableCell>
      <TableCell>Optimized resource utilization</TableCell>
    </TableRow>
  </TableBody>
</Table>

### Claude Model Family

<Card title="Model Selection Guide">
  <Table>
    <TableHead>
      <TableRow>
        <TableHeader>Model</TableHeader>
        <TableHeader>Best For</TableHeader>
        <TableHeader>Context Window</TableHeader>
        <TableHeader>Use Case</TableHeader>
      </TableRow>
    </TableHead>
    <TableBody>
      <TableRow>
        <TableCell><strong>Claude 3 Opus</strong></TableCell>
        <TableCell>Most intelligent, complex reasoning</TableCell>
        <TableCell>200K tokens</TableCell>
        <TableCell>Research, analysis, creative tasks</TableCell>
      </TableRow>
      <TableRow>
        <TableCell><strong>Claude 3 Sonnet</strong></TableCell>
        <TableCell>Balanced performance and speed</TableCell>
        <TableCell>200K tokens</TableCell>
        <TableCell>General business applications</TableCell>
      </TableRow>
      <TableRow>
        <TableCell><strong>Claude 3 Haiku</strong></TableCell>
        <TableCell>Fastest, most cost-effective</TableCell>
        <TableCell>200K tokens</TableCell>
        <TableCell>Simple tasks, high-volume processing</TableCell>
      </TableRow>
    </TableBody>
  </Table>
</Card>

## Why It's Important for Designers to Know

### 1. **Understanding Model Capabilities and Limitations**

<Card title="Model Understanding Framework">
  <ul>
    <li><strong>Context Windows:</strong> How much information a model can process at once</li>
    <li><strong>Token Limits:</strong> Understanding input/output constraints</li>
    <li><strong>Latency Characteristics:</strong> How long models take to respond</li>
    <li><strong>Accuracy Patterns:</strong> When models are reliable vs. uncertain</li>
    <li><strong>Bias and Safety:</strong> Understanding model limitations and risks</li>
  </ul>
</Card>

### 2. **Informing Interaction Design**

<Callout type="warning">
  **Critical Insight**: AI model limitations directly constrain what's possible in user interface design and interaction patterns.
</Callout>

<Table>
  <TableHead>
    <TableRow>
      <TableHeader>Model Limitation</TableHeader>
      <TableHeader>Design Implication</TableHeader>
      <TableHeader>Design Solution</TableHeader>
    </TableRow>
  </TableHead>
  <TableBody>
    <TableRow>
      <TableCell><strong>Context Window Limits</strong></TableCell>
      <TableCell>Can't process unlimited text</TableCell>
      <TableCell>Chunking, summarization, progressive disclosure</TableCell>
    </TableRow>
    <TableRow>
      <TableCell><strong>Latency</strong></TableCell>
      <TableCell>Response delays affect UX</TableCell>
      <TableCell>Loading states, streaming, optimistic updates</TableCell>
    </TableRow>
    <TableRow>
      <TableCell><strong>Uncertainty</strong></TableCell>
      <TableCell>Models can be wrong or uncertain</TableCell>
      <TableCell>Confidence indicators, fallbacks, user controls</TableCell>
    </TableRow>
    <TableRow>
      <TableCell><strong>Token Costs</strong></TableCell>
      <TableCell>Expensive to process large inputs</TableCell>
      <TableCell>Efficient prompting, caching, batching</TableCell>
    </TableRow>
  </TableBody>
</Table>

### 3. **Enabling Effective Collaboration**

<Card title="Shared Language with Engineers">
  <ul>
    <li><strong>Technical Constraints:</strong> Understand what's technically feasible</li>
    <li><strong>Performance Trade-offs:</strong> Balance quality vs. speed vs. cost</li>
    <li><strong>Architecture Decisions:</strong> Participate in system design discussions</li>
    <li><strong>User Experience Optimization:</strong> Design within technical boundaries</li>
  </ul>
</Card>

## Core AI Concepts

### 1. **Machine Learning Fundamentals**

<Accordion type="single" collapsible>
  <AccordionItem value="supervised-learning">
    <AccordionTrigger>Supervised Learning</AccordionTrigger>
    <AccordionContent>
      <Card title="Learning from Labeled Data">
        <p>Supervised learning involves training models on data where the correct answers are known.</p>
        
        <h4>Key Concepts:</h4>
        <ul>
          <li><strong>Training Data:</strong> Labeled examples used to teach the model</li>
          <li><strong>Validation:</strong> Testing on unseen data to assess performance</li>
          <li><strong>Overfitting:</strong> When a model memorizes training data instead of learning patterns</li>
          <li><strong>Generalization:</strong> Ability to perform well on new, unseen data</li>
        </ul>
        
        <h4>Design Implications:</h4>
        <ul>
          <li>Models need sufficient, high-quality training data</li>
          <li>Performance varies based on data quality and quantity</li>
          <li>Models may struggle with edge cases not in training data</li>
        </ul>
      </Card>
    </AccordionContent>
  </AccordionItem>
  
  <AccordionItem value="unsupervised-learning">
    <AccordionTrigger>Unsupervised Learning</AccordionTrigger>
    <AccordionContent>
      <Card title="Finding Patterns Without Labels">
        <p>Unsupervised learning discovers hidden patterns in data without predefined answers.</p>
        
        <h4>Key Concepts:</h4>
        <ul>
          <li><strong>Clustering:</strong> Grouping similar data points together</li>
          <li><strong>Dimensionality Reduction:</strong> Simplifying complex data representations</li>
          <li><strong>Anomaly Detection:</strong> Identifying unusual patterns or outliers</li>
        </ul>
        
        <h4>Design Implications:</h4>
        <ul>
          <li>Useful for exploratory data analysis</li>
          <li>Can reveal unexpected insights</li>
          <li>Results may be less predictable than supervised learning</li>
        </ul>
      </Card>
    </AccordionContent>
  </AccordionItem>
  
  <AccordionItem value="reinforcement-learning">
    <AccordionTrigger>Reinforcement Learning</AccordionTrigger>
    <AccordionContent>
      <Card title="Learning Through Trial and Error">
        <p>Reinforcement learning agents learn by taking actions and receiving rewards or penalties.</p>
        
        <h4>Key Concepts:</h4>
        <ul>
          <li><strong>Agent:</strong> The learning system that takes actions</li>
          <li><strong>Environment:</strong> The world in which the agent operates</li>
          <li><strong>Reward Function:</strong> Defines what constitutes success</li>
          <li><strong>Policy:</strong> The strategy for choosing actions</li>
        </ul>
        
        <h4>Design Implications:</h4>
        <ul>
          <li>Requires careful reward function design</li>
          <li>Can learn complex behaviors through interaction</li>
          <li>May take time to converge to optimal behavior</li>
        </ul>
      </Card>
    </AccordionContent>
  </AccordionItem>
</Accordion>

### 2. **Neural Networks and Deep Learning**

<Card title="Neural Network Fundamentals">
  <p>Neural networks are computational models inspired by biological brains, consisting of interconnected nodes (neurons) that process information.</p>
  
  <h4>Key Components:</h4>
  <ul>
    <li><strong>Input Layer:</strong> Receives the initial data</li>
    <li><strong>Hidden Layers:</strong> Process and transform the data</li>
    <li><strong>Output Layer:</strong> Produces the final result</li>
    <li><strong>Weights and Biases:</strong> Parameters that determine how information flows</li>
  </ul>
  
  <h4>Design Implications:</h4>
  <ul>
    <li>Models can learn complex, non-linear relationships</li>
    <li>Require significant computational resources</li>
    <li>Training can be time-consuming and expensive</li>
    <li>Results may be difficult to interpret (black box problem)</li>
  </ul>
</Card>

### 3. **Large Language Models (LLMs)**

<Card title="LLM Architecture and Capabilities">
  <p>Large Language Models are neural networks trained on vast amounts of text data to understand and generate human language.</p>
  
  <h4>Key Characteristics:</h4>
  <ul>
    <li><strong>Scale:</strong> Billions of parameters trained on massive datasets</li>
    <li><strong>Context Windows:</strong> Amount of text they can process at once</li>
    <li><strong>Emergent Abilities:</strong> Capabilities that appear at scale</li>
    <li><strong>Few-shot Learning:</strong> Ability to learn from examples</li>
  </ul>
  
  <h4>Claude-Specific Capabilities:</h4>
  <ul>
    <li><strong>200K Token Context:</strong> Can process very long documents</li>
    <li><strong>Tool Use:</strong> Can interact with external systems</li>
    <li><strong>Vision:</strong> Can analyze images and visual content</li>
    <li><strong>Safety:</strong> Built with constitutional AI principles</li>
  </ul>
</Card>

## Claude Implementation Framework

### 1. **Scoping Your Use Case**

<Card title="Use Case Definition">
  <h4>Key Questions:</h4>
  <ul>
    <li>What specific problem are you trying to solve?</li>
    <li>What are the success criteria and performance requirements?</li>
    <li>What are the cost and latency constraints?</li>
    <li>What level of accuracy and reliability is needed?</li>
  </ul>
  
  <h4>Claude-Specific Considerations:</h4>
  <ul>
    <li>Choose appropriate model (Opus, Sonnet, Haiku) based on complexity</li>
    <li>Consider context window requirements for your data</li>
    <li>Evaluate need for tool use or vision capabilities</li>
    <li>Assess security and compliance requirements</li>
  </ul>
</Card>

### 2. **Designing Your Integration**

<Card title="Integration Architecture">
  <h4>Deployment Options:</h4>
  <ul>
    <li><strong>Anthropic API:</strong> Direct integration with Claude models</li>
    <li><strong>AWS Bedrock:</strong> Managed Claude deployment on AWS</li>
    <li><strong>Google Vertex AI:</strong> Claude integration on Google Cloud</li>
    <li><strong>Custom Deployment:</strong> Self-hosted solutions</li>
  </ul>
  
  <h4>Capability Selection:</h4>
  <ul>
    <li><strong>Text Generation:</strong> Content creation, summarization, translation</li>
    <li><strong>Code Generation:</strong> Programming assistance, debugging</li>
    <li><strong>Vision Processing:</strong> Image analysis, document understanding</li>
    <li><strong>Tool Use:</strong> External API integration, function calling</li>
  </ul>
</Card>

### 3. **Preparing Your Data**

<Card title="Data Preparation">
  <h4>Context Management:</h4>
  <ul>
    <li><strong>Token Counting:</strong> Monitor input/output token usage</li>
    <li><strong>Context Optimization:</strong> Efficient use of 200K token window</li>
    <li><strong>Data Cleaning:</strong> Ensure high-quality inputs</li>
    <li><strong>Structured Data:</strong> Format data for optimal processing</li>
  </ul>
  
  <h4>Claude-Specific Data Considerations:</h4>
  <ul>
    <li>Leverage Claude's ability to handle long documents</li>
    <li>Use structured prompts for consistent outputs</li>
    <li>Consider multimodal inputs (text + images)</li>
    <li>Plan for tool integration if needed</li>
  </ul>
</Card>

### 4. **Developing Your Prompts**

<Card title="Prompt Engineering with Claude">
  <h4>Claude Best Practices:</h4>
  <ul>
    <li><strong>Be Clear and Direct:</strong> Claude responds well to explicit instructions</li>
    <li><strong>Use Examples:</strong> Few-shot prompting improves performance</li>
    <li><strong>Let Claude Think:</strong> Encourage step-by-step reasoning</li>
    <li><strong>Use XML Tags:</strong> Structure complex prompts effectively</li>
    <li><strong>Give Claude a Role:</strong> System prompts define behavior</li>
  </ul>
  
  <h4>Advanced Techniques:</h4>
  <ul>
    <li><strong>Chain of Thought:</strong> Encourage step-by-step reasoning</li>
    <li><strong>Few-shot Learning:</strong> Provide examples for complex tasks</li>
    <li><strong>Role Definition:</strong> Give Claude a specific persona</li>
    <li><strong>Iterative Refinement:</strong> Build complex prompts gradually</li>
  </ul>
</Card>

### 5. **Testing and Evaluation**

<Card title="Claude Evaluation Framework">
  <h4>Success Criteria:</h4>
  <ul>
    <li><strong>Accuracy:</strong> Measure correctness of outputs</li>
    <li><strong>Relevance:</strong> Assess alignment with user intent</li>
    <li><strong>Safety:</strong> Evaluate adherence to safety guidelines</li>
    <li><strong>Performance:</strong> Monitor latency and throughput</li>
  </ul>
  
  <h4>Testing Strategies:</h4>
  <ul>
    <li><strong>Red Teaming:</strong> Test for potential misuse</li>
    <li><strong>A/B Testing:</strong> Compare different approaches</li>
    <li><strong>User Testing:</strong> Gather real-world feedback</li>
    <li><strong>Automated Evaluation:</strong> Scale testing processes</li>
  </ul>
</Card>

### 6. **Safety and Guardrails**

<Card title="Claude Safety Features">
  <h4>Built-in Protections:</h4>
  <ul>
    <li><strong>Constitutional AI:</strong> Safety principles built into training</li>
    <li><strong>Jailbreak Resistance:</strong> Resistant to prompt injection attacks</li>
    <li><strong>Hallucination Reduction:</strong> Lower rates of false information</li>
    <li><strong>Content Filtering:</strong> Automatic detection of harmful content</li>
  </ul>
  
  <h4>Additional Guardrails:</h4>
  <ul>
    <li><strong>Output Validation:</strong> Verify Claude's responses</li>
    <li><strong>Input Sanitization:</strong> Clean user inputs</li>
    <li><strong>Rate Limiting:</strong> Prevent abuse</li>
    <li><strong>Monitoring:</strong> Track usage and behavior</li>
  </ul>
</Card>

## Real-World Applications

### 1. **Customer Support Systems**

<Card title="Claude in Customer Support">
  <h4>Use Cases:</h4>
  <ul>
    <li><strong>Ticket Routing:</strong> Automatically categorize and route support tickets</li>
    <li><strong>Response Generation:</strong> Create personalized, accurate responses</li>
    <li><strong>Knowledge Base Search:</strong> Find relevant information quickly</li>
    <li><strong>Escalation Detection:</strong> Identify cases needing human intervention</li>
  </ul>
  
  <h4>Claude Advantages:</h4>
  <ul>
    <li>200K context window handles long conversation histories</li>
    <li>Tool use enables integration with support systems</li>
    <li>Vision capabilities for analyzing screenshots and documents</li>
    <li>High accuracy reduces need for human oversight</li>
  </ul>
</Card>

### 2. **Content Creation and Management**

<Card title="Content Generation with Claude">
  <h4>Applications:</h4>
  <ul>
    <li><strong>Marketing Copy:</strong> Generate brand-consistent content</li>
    <li><strong>Technical Documentation:</strong> Create clear, accurate docs</li>
    <li><strong>Code Documentation:</strong> Explain complex codebases</li>
    <li><strong>Multilingual Content:</strong> Translate and localize materials</li>
  </ul>
  
  <h4>Claude Strengths:</h4>
  <ul>
    <li>Maintains brand voice and style consistency</li>
    <li>Handles technical topics with high accuracy</li>
    <li>Can process and reference source materials</li>
    <li>Supports multiple languages effectively</li>
  </ul>
</Card>

### 3. **Data Analysis and Insights**

<Card title="Analytics with Claude">
  <h4>Capabilities:</h4>
  <ul>
    <li><strong>Data Interpretation:</strong> Analyze complex datasets</li>
    <li><strong>Chart Analysis:</strong> Extract insights from visualizations</li>
    <li><strong>Report Generation:</strong> Create comprehensive summaries</li>
    <li><strong>Trend Identification:</strong> Spot patterns and anomalies</li>
  </ul>
  
  <h4>Claude Features:</h4>
  <ul>
    <li>Vision capabilities for chart and graph analysis</li>
    <li>Long context window for comprehensive reports</li>
    <li>Tool use for database queries and calculations</li>
    <li>Structured output for consistent formatting</li>
  </ul>
</Card>

## Best Practices for Claude Integration

### 1. **Model Selection**

<Card title="Choosing the Right Claude Model">
  <Table>
    <TableHead>
      <TableRow>
        <TableHeader>Use Case</TableHeader>
        <TableHeader>Recommended Model</TableHeader>
        <TableHeader>Reasoning</TableHeader>
      </TableRow>
    </TableHead>
    <TableBody>
      <TableRow>
        <TableCell>Simple Q&A, high volume</TableCell>
        <TableCell>Claude 3 Haiku</TableCell>
        <TableCell>Fast, cost-effective for straightforward tasks</TableCell>
      </TableRow>
      <TableRow>
        <TableCell>General business applications</TableCell>
        <TableCell>Claude 3 Sonnet</TableCell>
        <TableCell>Balanced performance and cost for most use cases</TableCell>
      </TableRow>
      <TableRow>
        <TableCell>Complex reasoning, research</TableCell>
        <TableCell>Claude 3 Opus</TableCell>
        <TableCell>Highest intelligence for challenging problems</TableCell>
      </TableRow>
    </TableBody>
  </Table>
</Card>

### 2. **Prompt Engineering**

<Card title="Effective Claude Prompting">
  <h4>Structure Your Prompts:</h4>
  <ul>
    <li><strong>Clear Instructions:</strong> Be specific about what you want</li>
    <li><strong>Context Provision:</strong> Provide relevant background information</li>
    <li><strong>Example Outputs:</strong> Show Claude the desired format</li>
    <li><strong>Constraints:</strong> Specify limitations and requirements</li>
  </ul>
  
  <h4>Advanced Techniques:</h4>
  <ul>
    <li><strong>Chain of Thought:</strong> Encourage step-by-step reasoning</li>
    <li><strong>Few-shot Learning:</strong> Provide examples for complex tasks</li>
    <li><strong>Role Definition:</strong> Give Claude a specific persona</li>
    <li><strong>Iterative Refinement:</strong> Build complex prompts gradually</li>
  </ul>
</Card>

### 3. **Performance Optimization**

<Card title="Optimizing Claude Performance">
  <h4>Context Management:</h4>
  <ul>
    <li><strong>Token Efficiency:</strong> Minimize unnecessary context</li>
    <li><strong>Structured Inputs:</strong> Organize information clearly</li>
    <li><strong>Caching:</strong> Store and reuse common responses</li>
    <li><strong>Batching:</strong> Process multiple requests together</li>
  </ul>
  
  <h4>Cost Optimization:</h4>
  <ul>
    <li><strong>Model Selection:</strong> Choose appropriate model for task complexity</li>
    <li><strong>Prompt Efficiency:</strong> Minimize input tokens</li>
    <li><strong>Response Limits:</strong> Set appropriate output constraints</li>
    <li><strong>Usage Monitoring:</strong> Track token consumption and costs</li>
  </ul>
</Card>

## Related Concepts

<CardGroup cols={3}>
  <Card title="Prompt Engineering" icon="edit" href="../prompting-techniques/chain-of-thought">
    Master the art of crafting effective prompts
  </Card>
  <Card title="Tool Use" icon="wrench" href="../prompting-techniques/react">
    Integrate external tools and APIs
  </Card>
  <Card title="Evaluation" icon="check-circle" href="../evaluation-observability">
    Measure and improve AI system performance
  </Card>
  <Card title="Safety" icon="shield" href="../safety-security">
    Build safe and trustworthy AI systems
  </Card>
  <Card title="Multimodality" icon="image" href="../multimodality">
    Work with text, images, and other data types
  </Card>
  <Card title="Enterprise AI" icon="building" href="../productization-mlops">
    Deploy AI systems at scale
  </Card>
</CardGroup>

> **Note:** The following article is reproduced verbatim from  
> Codecademy Team, *Codecademy* (2025):  
> [Getting Started with OpenAI Models](https://www.codecademy.com/article/getting-started-with-open-ai-models)  
> for internal educational use only (non-profit).

## Getting Started with OpenAI Models

Learn how to set up, use, and fine-tune OpenAI models for various applications. Get step-by-step guidance and tips on utilizing these powerful AI tools.

### Introduction

Artificial intelligence offers unprecedented opportunities, and OpenAI models are at the forefront of this revolution. This guide will discuss how to set up our environment, use an OpenAI model, and in the end how to finetune it to better fit tasks or topics.

### What are OpenAI Models used for?

OpenAI models lead the way in artificial intelligence development, particularly generative AI. These models, trained on vast amounts of data, can understand, and generate human-like text. OpenAI models like GPT-3.5 turbo are designed to perform a wide range of natural language processing tasks, including translation, question answering, and text generation. OpenAI models are used in various applications such as customer service automation, content creation, data analysis, etc.

### Examples of Popular OpenAI Models

OpenAI has released many generative AI models. One prominent example is GPT-3 (Generative Pre-trained Transformer 3). It can generate text, write code, create stories, and provide educational content. GPT-3.5-turbo, another popular model, excels in conversational AI applications. These models are widely used across industries to automate tasks, enhance customer interactions, and support data analysis, among other applications. Understanding how to utilize and customize these models can significantly enhance your projects. Let us explore the steps to get started with OpenAI models.

### Setting up OpenAI Models

Setting up OpenAI models involves creating an OpenAI account and configuring your development environment.

#### Signing Up with OpenAI

Begin by  registering for an account on the OpenAI website. After signing up, you'll gain access to API keys and comprehensive documentation essential for developing applications with OpenAI models.

#### Setting Up Your Development Environment

The development environment setup varies based on your preferred programming language or platform. Python is commonly used due to its simplicity and extensive library support. Install the necessary packages, such as openai, using pip:

```
pip install openai
```

Now navigate to your OpenAI account settings to obtain your API key. Keep this key secure, as it provides access to OpenAI models and safeguards your usage.

#### Sending API Requests to OpenAI Models

With the API key, you can send requests to OpenAI's API. Below is a simple example using Python:

```python
import openai
# Replace 'your_api_key' with your actual OpenAI API key
openai.api_key = 'your_api_key'
response = openai.completions.create(
    model="gpt-3.5-turbo-0125",
    prompt="Translate the following English text to French: 'Hello, how are you?'",
    max_tokens=60
)
print(response.choices[0].text.strip())
```

The above code sends a prompt to the gpt-3.5-turbo-0125 model for translation.

The parameter response function uses:

- **model**: Specifies the model to be used for generating the completion.
- **prompt**: The text you provide as input for the model to generate a response.
- **max_tokens**: Limits the length of the generated response.

### How to Use OpenAI Models for Various Tasks

OpenAI offers a range of models tailored to different tasks. For instance, gpt-3.5-turbo-0125 excels at text generation and analysis, GPT-3.5-turbo is ideal for conversational tasks, DALL·E is used for creating and editing images based on prompts, and Whisper is designed to convert audio into text. Select a model that fits your specific use case. Refer to OpenAI's model documentation for more details.

#### Using OpenAI Models for Text Generation and More

Once you have selected a model, you can send structured prompts and handle responses. Here's another example using the gpt-3.5-turbo-0125 model for summarization:

```python
import openai
# Replace 'your_api_key' with your actual OpenAI API key
openai.api_key = 'your_api_key'
response = openai.Completion.create(
    engine="gpt-3.5-turbo-0125",
    prompt="Summarize the following article: 'OpenAI has announced ...'",
    max_tokens=150
)
print(response.choices[0].text.strip())
```

By using different prompts, we can perform tasks like text summarization, translation, and question answering.

### How to Fine-Tune an OpenAI Model

Fine-tuning OpenAI models involve training a pre-existing model further using specific data, tailoring it to better fit tasks or topics. This process enhances the model's performance, making it more accurate for your needs.

#### Fine Tuning OpenAI Model

To fine-tune an OpenAI model, follow these steps:

1. **Prepare Your Dataset**: Gather and clean a text dataset relevant to your application.
2. **Upload the Dataset**: Use OpenAI's data management tools to upload your dataset.
3. **Initiate Fine-Tuning**: Start the fine-tuning process using the OpenAI API.

Here's an example:

```python
import openai
# Replace 'your_api_key' with your OpenAI API key
openai.api_key = 'your_api_key'
response = openai.FineTune.create(
    training_file='path/to/your/training_dataset.json',
    model="gpt-3.5-turbo-0125"
)
print("Fine tune job initiated:", response)
```

4. **Monitor and Evaluate**: Track the fine-tuning progress and evaluate the results using validation datasets to ensure effectiveness.

#### Conclusion

We've explored how to get started with OpenAI models, from setting up and making API calls to choosing and fine-tuning models. This knowledge enables the integration of advanced AI into your projects, driving productivity and innovation. By mastering the use and customization of these models, we can tailor them to meet specific needs, ensuring your applications are as effective and efficient as possible.

> **Note:** The following article is reproduced verbatim from  
> Codecademy Team, *Codecademy* (2025):  
> [What is Reinforcement Learning? With Examples](https://www.codecademy.com/article/what-is-reinforcement-learning-with-examples)  
> for internal educational use only (non-profit).

## What is Reinforcement Learning? With Examples

### What is reinforcement learning (RL)?

Reinforcement learning (RL) is a machine learning approach where an AI agent learns to make optimal decisions through trial and error, receiving rewards for good actions and penalties for bad ones. Imagine teaching a dog to sit. You reward it with a treat when it obeys and penalize it when it doesn't. Over time, the dog learns to repeat actions that earn rewards and avoid those that lead to penalties. This same principle guides how RL trains AI agents.

A typical reinforcement learning setup looks as follows:

![Diagram showing reinforcement learning process with agent, environment, actions, states and rewards in a continuous feedback loop](https://static-assets.codecademy.com/reinforcement-learning/reinforcement_learning.jpg)
<sub>Source: *Codecademy*, Codecademy Team (2025).</sub>

Here, we have an agent being trained using reinforcement learning.

- The agent takes an action in the given environment.
- The state of the environment changes due to the action, and the agent receives a reward or penalty.
- Based on the current action, the current state of the environment, the new state of the environment after the action, and the reward received, the agent chooses the next action carefully to maximize its rewards.

The reinforcement learning process happens iteratively in three steps. Before discussing how RL works, let's discuss different components in an RL setup.

### Components of a reinforcement learning system

A reinforcement learning setup includes an agent, environment, states, actions, policy, reward, and value function.

- **Agent**: An agent is the learner or decision maker. It interacts with the environment, learns from its experience, and performs actions based on what it has learned so far during training.
- **Environment**: It is the world the agent lives in. The environment consists of everything the agent interacts with and responds to the agent's actions by giving new states and rewards.
- **States**: States represent all the possible scenarios for a given environment. A state provides a snapshot of the current situation and helps the agent decide what to do next.
- **Actions**: Actions include the number of choices an agent can make. Every action performed by an agent changes the environment in some way.
- **Reward**: Reward is a feedback signal that tells the agent how good or bad its action was.
- **Policy**: Policy is the strategy the agent follows to choose an action in a given state. The policy maps states to actions and helps the agent decide what action to take in a given state. It can be deterministic or non-deterministic.
- **Value function**: The value function measures how good a state or action is regarding future rewards. It measures how good it is to be in a state or how good an action is in a particular state.

Now that we know the different components of a reinforcement learning setup, let's discuss how reinforcement learning works.

### How does reinforcement learning work?

Reinforcement learning involves three steps: exploration, feedback, and adjustment. Let's discuss each process separately.

#### Exploration

When an agent is put into a given state in the environment, it won't know the action that offers the best rewards. Hence, it explores different actions using trial and error to see what happens. Exploration is useful as it helps the agent try different actions in a given state, which results in the agent finding the best action for the current state.

For example, if a robot learning to move from source to destination in a maze takes the right at every cell it reaches, it might never find the fastest path to the goal. However, the robot can explore going left, right, and forward, which can result in finding the shortest path.

#### Feedback

Every action taken by the agent changes the state of the environment. The reward model gives the agent feedback based on how good the action was. The feedback helps the agent decide whether an action was good or bad in the long run.

For example, if a step in the maze gets the robot closer to the goal, it might get +10 points. If the robot rams into a wall, it might get -5 points. Hence, the robot will always try to move in a direction that gets it closer to the goal.

#### Adjustment

The agent updates its policy in response to feedback. This helps the agent make better decisions by choosing actions that led to higher rewards in the past.

- If the agent is rewarded after an action in a given state, it adjusts its policy to repeat the same action in the future if it encounters the same state.
- If the agent is penalized after an action, it adjusts its policy to avoid the action in the future.

By iteratively exploring different actions and making adjustments, the agent updates its policy to achieve the highest rewards in a given state. Eventually, the agent learns to complete the task optimally.

Let's discuss some reinforcement learning examples to understand how the exploration, feedback, and adjustment steps work.

### Reinforcement learning examples

We will discuss three examples to understand how reinforcement learning works.

#### Example 1: Game playing

AI agents are trained to play board games like Chess or Atari. In such games, reinforcement learning works as follows:

- **Exploration**: During exploration, the agent tries random moves to see how they affect the game.
- **Feedback**: The agent receives feedback in terms of points. Losing points or pieces means a negative reward, while getting points means a positive reward. The rewards are also decided based on whether the agent moves closer to a win or a loss after an action.
- **Adjustment**: The agent updates its policy to prefer moves that lead to wins or higher scores.

Over time, the agent learns strategies that win more games.

#### Example 2: Online advertisement placement

An agent trying to learn how to give the best advertisements to the audience is trained using reinforcement learning as follows:

- **Exploration**: The agent shows different types of ads to the audience.
- **Feedback**: If the user clicks on an ad, it means a positive reward. For conversions, the agent receives higher rewards. The agent gets a neutral or negative reward if the user doesn't interact with the ad.
- **Adjustment**: The agent learns to select ad types, content, and platforms that lead to more clicks and conversions.

After being trained for a long time using the feedback data from ads, the agent learns user preferences and targets ads more effectively, resulting in an increase in return on ad spend.

#### Example 3: Algorithmic trading

Algorithmic trading uses AI agents to buy and sell stocks in a fraction of a second. An agent for algorithmic trading is trained as follows:

- **Exploration**: The trading agent experiments with various buying/selling strategies based on a stock's given state.
- **Feedback**: Profits and losses from trades are rewards and penalties. If an action results in a loss, the agent tries to avoid it in the future. If an action leads to profits, the agent is more likely to repeat the action.
- **Adjustment**: The agent refines its policy to maximize the overall profit and avoid risky trades.

Over time, agents become sophisticated and execute automated trades that generate significant profits for companies like Tower Research Capital, Jane Street, and Hudson River Trading.

Having discussed how reinforcement learning works, let's discuss the different types of reinforcement learning, which will help you understand how the feedback and adjustments work in an RL setup.

### Types of reinforcement learning

We can categorize reinforcement learning based on learning approach and policy-optimization methods.

#### Reinforcement learning types based on learning approach

We can categorize reinforcement learning into two types based on the learning approach, i.e., model-free RL and model-based RL.

- **Model-free RL**: In model-free reinforcement learning, the agent learns without building a model of the environment. Instead, it focuses on learning a policy or value function directly through trial and error. Examples of model-free RL include Q-learning and the State-action-reward-state-action (SARSA) algorithm.
- **Model-based RL**: In model-based reinforcement learning, the agent models the environment to predict future states and rewards. This helps the agent plan actions by simulating future steps without interacting with the environment. Examples of model-based RL include the Dyna-Q and Monte Carlo tree search algorithms.

#### Reinforcement learning types based on policy optimization

Model-free reinforcement learning can be categorized into three types, i.e., policy-based RL, value-based RL, and actor-critic methods.

- **Policy-based reinforcement learning**: In policy-based RL, the agent directly estimates the optimal policy. For this, the agent represents the policy as a combination of learnable parameters and converts the training process into an optimization problem. Then, the agent samples the different trajectories and rewards and uses the information to improve the policy by optimizing the average value function across all the states in the environment. Policy-based RL is useful for high-dimensional or continuous spaces. Examples of policy-based RL include Proximal Policy Optimization (PPO), Monte Carlo Policy Gradient (REINFORCE), and Deterministic Policy Gradient (DPG).
- **Value-based reinforcement learning**: In value-based RL, the agent assumes that the optimal policy can be derived by accurately estimating the value function of every state. Using Bellman equation, the agent tries to find all the paths in the environment and the associated rewards. In this process, the agent finds the optimal value function that provides the value of states or state-action pairs. Then, the agent acts greedily at every step to find the optimal path. SARSA and Q-learning are value-based reinforcement learning methods. Note that value-based RL doesn't directly optimize the policy.
- **Actor-critic methods**: Actor-critic methods combine policy-based and value-based RL. In this approach, the agent has two components, i.e., the actor and the critic. The actor updates the policy function, whereas the critic evaluates the action using the value function. In other words, the actor is responsible for what action will lead to long-term rewards, and the critic evaluates how good an action is. Examples of actor-critic methods include Asynchronous Advantage Actor-Critic (A3C), Advantage Actor-Critic (A2C), and Deep Deterministic Policy Gradient (DDPG).

We have discussed the working and types of reinforcement learning. Now, let's discuss its advantages and disadvantages.

### Advantages and disadvantages of reinforcement learning

Due to its training approach, reinforcement learning has many advantages:

- **Solving complex problems**: In many situations, we cannot model every state of the environment. In such cases, reinforcement learning (RL) helps us explore different paths to reach the optimal solution. RL works even if the states and rewards are non-deterministic and may change over time, which makes it useful for many industry applications.
- **Continuous improvement**: The RL agent updates its strategy according to each action and the reward it receives. Hence, the model continuously learns from its past and uses its learnings to take actions that maximize the rewards in the future.
- **RL Works with delayed feedback**: For use cases like online advertisement placement or product recommendation systems, feedback might get delayed for several reasons. For such cases, RL works well by optimizing for long-term rewards. Traditional supervised learning algorithms like linear regression or convolutional neural networks don't work with delayed feedback.
- **Avoids explicit modeling**: Traditional supervised learning methods require labeled data and a defined algorithm for model training. On the contrary, model-free RL methods do not require us to prepare datasets or build complex models of the environment. We can skip modeling the environment if it is infeasible or too complex. Even then, reinforcement learning works well.

Despite all the advantages of the non-deterministic and adaptive learning approach in reinforcement learning, we also encounter some challenges.

- **Sample insufficiency**: Reinforcement learning requires a huge number of interactions with the environment for the agent to learn how to behave. This can be infeasible for real-world applications where collecting feedback is slow. Even simulating the environment in a controlled system can incur huge costs, which makes RL infeasible in many cases.
- **Training instability**: The training process can become unstable if the state transitions in a reinforcement learning system are very complex and there is a high variance in updates. Hence, we need to design reward models and parameter updates to avoid divergence.
- **Reward design**: Designing an appropriate reward function that leads to desired behavior is challenging. Poorly designed reward models can cause unintended or suboptimal agent behavior. Hence, the reward model should be designed to ensure that the agent behaves harmlessly and safely. In real-world applications like robots or self-driving cars, we also need to ensure extensive safeguards to prevent the agent from becoming unsafe.
- **Resource requirement**: Reinforcement learning needs significant computational resources. Hence, training RL models can be expensive and time-consuming.

The advantages of reinforcement learning often outweigh its challenges, and many companies use RL to build AI systems. Let's discuss some applications of RL across various industries.

### Use cases and applications for reinforcement learning

Reinforcement learning is used in various domains, including finance, automobile, robotics, retail, and e-commerce. Let's discuss some use cases of reinforcement learning in each sector.

#### Finance

In finance, reinforcement learning is used in portfolio management, algorithmic trading, and risk management. The RL agents are trained for different use cases, such as dynamic asset allocation based on market conditions, implementing optimal trading strategies by interacting with market data, and adaptive hedging strategies for minimizing risks while maintaining good returns.

#### Automobile

The automobile sector uses reinforcement learning for self-driving cars, fleet management, and traffic control. Self-driving vehicles use reinforcement learning to learn driving policies for navigation, lane changing, and obstacle avoidance. Similarly, fleet management applications use RL for dynamic route planning for ride-sharing or delivery vehicles. In traffic control, RL optimizes traffic light timings to reduce congestion.

#### Robotics

Robots are used across industries to perform repetitive tasks efficiently and accurately. Companies use reinforcement learning to teach robots to walk, balance, and navigate uneven terrain. They are also trained to handle objects and plan paths in dynamic environments.

#### Retail and e-commerce

In retail and e-commerce, reinforcement learning is used to train models for creating dynamic pricing, recommendations, and retargeting applications. Using the customer journey data, RL applications are trained to show dynamic prices to users to maximize revenue. Similarly, product recommendation and retargeting systems use the user's click and conversion data as feedback to derive sales.

Reinforcement learning also plays a huge role in training generative AI applications like ChatGPT and Gemini to produce correct outputs without any discrimination or bias. For this, we use reinforcement learning with human feedback (RLHF). Let's discuss what RLHF is.

### Reinforcement learning with human feedback (RLHF)

Reinforcement learning with human feedback (RLHF) combines traditional reinforcement learning with human guidance to fine-tune LLMs. It allows an agent to learn desirable behavior from human-provided feedback such as preferences, corrections, or demonstrations.

For example, ChatGPT sometimes provides two outputs for a query and asks users to select the better response. Using your preference, it shapes its future output. During training, the LLM generates multiple outputs for a given query. Then, the outputs are ranked by humans and provided as feedback to the LLM. Based on the rankings, the LLM learns to generate answers that fetch better rankings. In this way, RLHF combines RL with human guidance.

RLHF helps us generate polite, accurate, and safe responses from LLMs by aligning AI responses with human values. It also finds its applications in robotics, where we use it to train robot behaviors by observing and ranking their actions.

### Conclusion

Reinforcement learning is an evolving area of machine learning. From game-playing AI agents to robotics and personalized recommendations, RL is already significantly impacting industries. While it offers promising advantages, it also comes with challenges like high computational cost and complexity. With advancements like RLHF, the field continues to grow in capability and accessibility.

This article discussed the basics of reinforcement learning with its components and working. We also discussed the examples, advantages, disadvantages, and applications of RL along with RLHF.

> **Note:** The following article is reproduced verbatim from  
> Smashing Magazine Team, *Smashing Magazine* (2025):  
> [A High-Level Overview Of Large Language Model Concepts, Use Cases, And Tools](https://www.smashingmagazine.com/2023/10/overview-large-language-model-concepts-use-cases-tools/)  
> for internal educational use only (non-profit).

# A High-Level Overview Of Large Language Model Concepts, Use Cases, And Tools

Even though a simple online search turns up countless tutorials on using Artificial Intelligence (AI) for everything from generative art to making technical documentation easier to use, there's still plenty of mystery around it. What goes inside an AI-powered tool like ChatGPT? How does Notion's AI feature know how to summarize an article for me on the fly? Or how are a bunch of sites suddenly popping up that can aggregate news and auto-publish a slew of "new" articles from it?

It all can seem like a black box of mysterious, arcane technology that requires an advanced computer science degree to understand. What I want to show you, though, is how we can peek inside that box and see how everything is wired up.

Specifically, this article is about large language models (LLMs) and how they "imbue" AI-powered tools with intelligence for answering queries in diverse contexts. I have previously written tutorials on how to use an LLM to transcribe and evaluate the expressed sentiment of audio files. But I want to take a step back and look at another way around it that better demonstrates — and visualizes — how data flows through an AI-powered tool.

We will discuss LLM use cases, look at several new tools that abstract the process of modeling AI with LLM with visual workflows, and get our hands on one of them to see how it all works.

## Large Language Models Overview

Forgoing technical terms, LLMs are vast sets of text data. When we integrate an LLM into an AI system, we enable the system to leverage the language knowledge and capabilities developed by the LLM through its own training. You might think of it as dumping a lifetime of knowledge into an empty brain, assigning that brain to a job, and putting it to work.

"Knowledge" is a convoluted term as it can be subjective and qualitative. We sometimes describe people as "book smart" or "street smart," and they are both types of knowledge that are useful in different contexts. This is what artificial "intelligence" is created upon. AI is fed with data, and that is what it uses to frame its understanding of the world, whether it is text data for "speaking" back to us or visual data for generating "art" on demand.

### Use Cases

As you may imagine (or have already experienced), the use cases of LLMs in AI are many and along a wide spectrum. And we're only in the early days of figuring out what to make with LLMs and how to use them in our work. A few of the most common use cases include the following.

- **Chatbot**: LLMs play a crucial role in building chatbots for customer support, troubleshooting, and interactions, thereby ensuring smooth communications with users and delivering valuable assistance. Salesforce is a good example of a company offering this sort of service.
- **Sentiment Analysis**: LLMs can analyze text for emotions. Organizations use this to collect data, summarize feedback, and quickly identify areas for improvement. Grammarly's "tone detector" is one such example, where AI is used to evaluate sentiment conveyed in content.
- **Content Moderation**: Content moderation is an important aspect of social media platforms, and LLMs come in handy. They can spot and remove offensive content, including hate speech, harassment, or inappropriate photos and videos, which is exactly what Hubspot's AI-powered content moderation feature does.
- **Translation**: Thanks to impressive advancements in language models, translation has become highly accurate. One noteworthy example is Meta AI's latest model, SeamlessM4T, which represents a big step forward in speech-to-speech and speech-to-text technology.
- **Email Filters**: LLMs can be used to automatically detect and block unwanted spam messages, keeping your inbox clean. When trained on large datasets of known spam emails, the models learn to identify suspicious links, phrases, and sender details. This allows them to distinguish legitimate messages from those trying to scam users or market illegal or fraudulent goods and services. Google has offered AI-based spam protection since 2019.
- **Writing Assistance**: Grammarly is the ultimate example of an AI-powered service that uses LLM to "learn" how you write in order to make writing suggestions. But this extends to other services as well, including Gmail's "Smart Reply" feature. The same thing is true of Notion's AI feature, which is capable of summarizing a page of content or meeting notes. Hemmingway's app recently shipped a beta AI integration that corrects writing on the spot.
- **Code and Development**: This is the one that has many developers worried about AI coming after their jobs. It hit the commercial mainstream with GitHub Copilot, a service that performs automatic code completion. Same with Amazon's CodeWhisperer. Then again, AI can be used to help sharpen development skills, which is the case of MDN's AI Help feature.

Again, these are still the early days of LLM. We're already beginning to see language models integrated into our lives, whether it's in our writing, email, or customer service, among many other services that seem to pop up every week. This is an evolving space.

## Types Of Models

There are all kinds of AI models tailored for different applications. You can scroll through Sapling's large list of the most prominent commercial and open-source LLMs to get an idea of all the diverse models that are available and what they are used for. Each model is the context in which AI views the world.

Let's look at some real-world examples of how LLMs are used for different use cases.

**Natural Conversation**: Chatbots need to master the art of conversation. Models like Anthropic's Claude are trained on massive collections of conversational data to chat naturally on any topic. As a developer, you can tap into Claude's conversational skills through an API to create interactive assistants.

**Emotions**: Developers can leverage powerful pre-trained models like Falcon for sentiment analysis. By fine-tuning Falcon on datasets with emotional labels, it can learn to accurately detect the sentiment in any text provided.

**Translation**: Meta AI released SeamlessM4T, an LLM trained on huge translated speech and text datasets. This multilingual model is groundbreaking because it translates speech from one language into another without an intermediary step between input and output. In other words, SeamlessM4T enables real-time voice conversations across languages.

**Content Moderation**: As a developer, you can integrate powerful moderation capabilities using OpenAI's API, which includes a LLM trained thoroughly on flagging toxic content for the purpose of community moderation.

**Spam Filtering**: Some LLMs are used to develop AI programs capable of text classification tasks, such as spotting spam emails. As an email user, the simple act of flagging certain messages as spam further informs AI about what constitutes an unwanted email. After seeing plenty of examples, AI is capable of establishing patterns that allow it to block spam before it hits the inbox.

## Not All Language Models Are Large

While we're on the topic, it's worth mentioning that not all language models are "large." There are plenty of models with smaller sets of data that may not go as deep as ChatGPT 4 or 5 but are well-suited for personal or niche applications.

> **Note:** The following article is reproduced verbatim from  
> Smashing Magazine Team, *Smashing Magazine* (2025):  
> [How To Use Artificial Intelligence And Machine Learning To Summarize Chat Conversations](https://www.smashingmagazine.com/2023/07/artificial-intelligence-machine-learning-summarize-chat-conversations/)  
> for internal educational use only (non-profit).

# How To Use Artificial Intelligence And Machine Learning To Summarize Chat Conversations

As developers, we often deal with large volumes of text, and making sense of it can be a challenge. In many cases, we might only be interested in a summary of the text or a quick overview of its main points. This is where text summarization comes in.

Text summarization is the process of automatically creating a shorter version of a text that preserves its key information. It has many applications in natural language processing (NLP), from summarizing news articles to generating abstracts for scientific papers. Even products, including Notion, are integrating AI features that will summarize a block of text on command.

![A screenshot of the Notion interface showing the option of using AI intelligence to write text, pages, and so on.](https://res.cloudinary.com/indysigner/image/fetch/f_auto,q_80/w_400/https://files.smashing.media/articles/artificial-intelligence-machine-learning-summarize-chat-conversations/notion-ai-technology.png)
<sub>Source: *Smashing Magazine*, Smashing Magazine Team (2025).</sub>

One interesting use case is summarizing chat conversations, where the goal is to distill the main topics and ideas discussed during the conversation. That's what we are going to explore in this article. Whether you're an experienced developer or just getting started with natural language processing, this article will provide a practical guide to building a chat summarizer from scratch. By the end, you'll have a working chat summarizer that you can use to extract the main ideas from your own chat conversations — or any other text data that you might encounter in your projects.

The best part about all of this is that accessing and integrating these sorts of AI and NLP capabilities is easier than ever. Where something like this may have required workarounds and lots of dependencies in the not-so-distant past, there are APIs and existing models readily available that we can leverage. I think you may even be surprised by how few steps there are to pull off this demo of a tool that summarizes chat conversations.

## Cohere: Chat Summarization Made Easy

Cohere is a cloud-based natural language processing platform that enables developers to build sophisticated language models without requiring deep expertise in machine learning. It offers a range of powerful tools for text classification, entity extraction, sentiment analysis, and more. One of its most popular features is chat summarization, which can automatically generate a summary of a conversation.

Using Cohere API for chat summarization is a simple and effective way to summarize chat conversations. It requires only a few lines of code to be implemented and can be used to summarize any chat conversation in real-time.

The chat summarization function of Cohere works by using natural language processing algorithms to analyze the text of the conversation. These algorithms identify important sentences and phrases, along with contextual information like speaker identity, timestamps, and sentiment. The output is a brief summary of the conversation that includes essential information and main points.

## Using The Cohere API For Chat Summarization

Now that we have a basic understanding of Cohere API and its capabilities, let's dive into how we can use it to generate chat summaries. In this section, we will discuss the step-by-step process of generating chat summaries using Cohere API.

To get started with the Cohere API, first, you'll need to sign up for an API key on the Cohere website. Once you have an API key, you can install the Cohere Python package using pip:

```
pip install cohere
```

Next, you'll need to initialize the cohere client by providing the API key:

```
import cohere

# initialize Cohere client
co = cohere.Client("YOUR_API_KEY")
```

Once the client is initialized, we can provide input for the summary. In the case of chat summarization, we need to provide the conversation as input. Here's how you can provide input for the summary:

> **Note:** The following article is reproduced verbatim from  
> NN/g Team, *Nielsen Norman Group* (2025):  
> [How AI Models Are Trained](https://www.nngroup.com/articles/ai-model-training/)  
> for internal educational use only (non-profit).

# How AI Models Are Trained

By this point, you've undoubtedly heard that the large language model (LLM) behind your favorite AI tool has been "trained on the whole internet." To some extent, that's true, but after training hundreds of UX professionals on how to use AI in their work, it's clear that many don't understand how the AI is trained. This is crucial for forming an accurate mental model of how these LLMs work, their limitations, and their capabilities.

This article discusses four basic types of training, when these are performed within an LLM, and how they impact the role of AI in user experience.

## In This Article:

- 1. The Pretraining Phase: Unsupervised Learning
- 2. The Finetuning Phase: Supervised Learning
- 3. Advanced Finetuning: Reinforcement Learning with Human Feedback (RLHF)
- LLMs Differ from Search Engines
- Environmental and Labor Costs

## 1. The Pretraining Phase: Unsupervised Learning

When you've heard that large language models have been "trained on the whole internet," people are typically talking about the pretraining phase, which involves unsupervised learning.

During this phase, the model is fed enormous amounts of text and data scraped from the internet, digitized books, code repositories, and more. One example of such datasets is Common Crawl, which has terabytes of data from billions of webpages. Cleaning these massive datasets before use requires significant effort.

The sheer volume of data makes it impossible for humans to label or explain it all. Instead, the model learns patterns on its own by trying to predict the next word (or "token") in a sequence.

From exposure to word combinations across billions of examples, the model learns grammar, facts, reasoning abilities (of a sort), and even the biases present in the data.

During the pretraining phase, the AI model is not learning specific tasks or 'meaning' in the human sense. It's pretty much all statistical relationships: which words are most likely to follow other words in different contexts.

### Unsupervised Learning Is Like a Toddler

Think of unsupervised learning like a toddler immersed in language for the first two years of life. They hear countless conversations. They aren't explicitly taught every grammatical rule, but they start absorbing patterns.

Eventually, they begin stringing words together in ways that mimic what they've heard, sometimes surprising you with sentences they weren't directly taught and whose meaning they don't fully grasp.

### Unsupervised Learning for AI-Based Design

While models differ in the types of training data they use, the patterns they learn, and how they rely on these patterns while generating outputs, the principle is the same.

Take Figma AI as an example: for its generative AI features, it needs a large amount of training data as a solid foundation. However, rather than starting from scratch and pretraining a brand new model by feeding it many designs created in Figma (which would have major privacy issues and be extremely costly), they used "third-party, out-of-the-box AI models." These third-party models call APIs from more robust AI companies, like perhaps OpenAI.

So, how can Figma AI generate user interfaces if it relies on models pretrained on text? Because the pretraining datasets they're using are so vast, they've processed billions of lines of code and learned the patterns in how interfaces are put together. However, this doesn't guarantee that asking it to "create a dashboard to display recent sales data" will create something useful, accessible, or reasonable. That requires finetuning.

## 2. The Finetuning Phase: Supervised Learning

If the pretraining phase teaches the model about raw patterns, the finetuning phase (which uses supervised learning) is like giving it specific lessons and examples.

Now, the toddler is older and you're sending them off to school, where a teacher will give them many examples of correct and incorrect sentences. These carefully selected examples are meant to teach the child how to use the vast vocabulary they acquired during unsupervised learning.

To train AI models, researchers create much smaller datasets containing carefully crafted examples of inputs (prompts) and desired outputs (responses).

For instance, a researcher might write a specific prompt and pair it with an ideal response they want the model to emulate. They might even create several variations of the response and rate them on criteria like helpfulness, clarity, or safety. By showing the model thousands of these carefully crafted examples, they teach it to use the patterns identified during pretraining in useful, truthful ways that are aligned with human expectations. Note that the researchers are still providing all their guidance at input. They are not paying much attention yet to the AI's outputs.

![A model response to a prompt about assistive devices, with scores for helpfulness, correctness, coherence, complexity, and verbosity.](https://media.nngroup.com/media/editor/2025/05/01/code2.png)
<sub>Source: *Nielsen Norman Group*, NN/g Team (2025).</sub>

Supervised-learning datasets are much smaller than those used for unsupervised learning but require significant human effort and cost to create. This phase is crucial for specializing the model and improving its ability to follow instructions.

However, bias can creep in here too. The data used for pretraining already contains societal biases (e.g., due to certain demographics or viewpoints being overrepresented online). During finetuning, the specific examples created and rated by humans also introduce the raters' perspectives, values, and potential biases.

Different labeling-data teams might instill slightly different "manners" in the model. This is partly why even LLMs that were trained on vast amounts of the same data can have different tones, personalities, and approaches. They've been finetuned slightly differently.

### Supervised Learning for AI-Based Design

Supervised learning isn't just for chatbots. Even Figma has finetuned some of its AI features to improve the outputs, though it mentions only features like Visual Search, Asset Search, and Add Interactions — not the text-to-UI features First Draft or AI Prototyping.

Figma's finetuning used "data from public, free community files" — that is, it relied on freely available designs rather than on high-quality ones created or vetted by Figma employees — a sensible approach that is cheap, quick, and doesn't violate any privacy restrictions. However, to return to our analogy, the toddler's "teacher" is using free examples from the internet rather than a curriculum designed by experts.

This does not mean that Figma AI will fail to produce anything useful; it simply means that the outputs are strongly biased toward the patterns available in the free, public files. Don't be surprised if the outputs feel generic — Figma itself says, "we need to train models that better understand design concepts and patterns."

Only when AI tools for creating UIs have been carefully finetuned by expert designers will we see as much nuanced power in AI-generated UI design as we currently see in AI-generated language.

## 3. Advanced Finetuning: Reinforcement Learning with Human Feedback (RLHF)

This final type of training is an advanced fine-tuning technique that relies on human judgment of the model's outputs. Now the child is doing writing exercises using the vocabulary they've absorbed (unsupervised learning) according to the rules and examples they've been taught (supervised learning). The teacher provides feedback on the child's work. Then the child adjusts their process based on the teacher's immediate feedback.

Reinforcement learning with human feedback is much the same: humans coach the AI model based on its outputs, often guided by how they feel about the outputs when the success criteria are difficult to define. For tasks with clear, reliable success criteria, such as a robotaxi safely navigating to a predetermined destination without crashing, AI models can iteratively learn on their own based on success or failure (often simply called reinforcement learning).

But what happens when success isn't easily defined by a simple rule, such as the difference between good and bad or useful and not useful?

RLHF brings humans into the loop during the reinforcement-learning process. The model might generate two or more responses to a prompt. A human labeler is then asked to rank these responses — which is better? More helpful? More harmless?

If you've ever been presented with multiple versions of a response while using an LLM, you have been involved in RLHF. Gathering this feedback from real users allows AI companies to gather feedback reflecting real user preferences at scale.

![Two ChatGPT responses with different layouts of information. At the top, it asks users to choose which they like better.](https://media.nngroup.com/media/editor/2025/05/01/screenshot-2025-03-26-at-35053-pm-1.png)
<sub>Source: *Nielsen Norman Group*, NN/g Team (2025).</sub>

> **Note:** The following article is reproduced verbatim from  
> NN/g Team, *Nielsen Norman Group* (2025):  
> [Four AI Superpowers: Where AI Improves Products](https://www.nngroup.com/articles/ai-superpowers/)  
> for internal educational use only (non-profit).

# Four AI Superpowers: Where AI Improves Products

At Pendo's Pendomonium conference recently, I asked my audience who had AI features on their product's roadmap. Almost every hand in the room went up. But, based on my experience, I'm guessing many of those AI-powered features are destined to be useless.

## In This Article:

- Start from the Problem, Not the Technology
- Is GenAI the Right Solution? The Superpowers of AI
- Appropriate use of AI

## Start from the Problem, Not the Technology

Amidst the AI hype, teams fall into a familiar trap of creating solutions in search of a problem. No one needs a half-baked chatbot that clumsily answers questions better suited for an FAQ. Users want solutions that effectively address user needs, regardless of the technology behind them.

Building effective solutions starts with choosing the right tool for the job. Generative AI (genAI) is a powerful tool, but it's not the only one.

I've advised dozens of product teams on their AI strategy. But even thinking about AI, product teams should have:

- A research-backed understanding of the existing customer problem
- A clear definition of desired outcomes and user behaviors

(I've done this so often, I created a framework to map these connections out — the user outcome connection.)

Only when the team is aligned on its goals, is it ready to decide if AI is the right option. The key question for the team to ask is:

> "Will generative AI make the user more likely to engage in the specific behavior that leads to the desired outcome and creates a positive impact for the business?"

Over the last year, I have been in many conversations where asking this question makes teams realize that genAI isn't what they need. For example, one team was in the middle of developing a chatbot to collect insights from users when a simple survey would have been much more effective at accomplishing that goal.

## Is GenAI the Right Solution? The Superpowers of AI

There is no one-size-fits-all answer to this question, especially since this technology is so new and rapidly evolving. These are tasks where genAI technology often excels and delivers value. I call them the superpowers of AI.

Currently available LLMs are particularly good at:

- **Creating content**
- **Summarizing text**
- **Basic data analysis**
- **Perspective taking**

Using genAI for such tasks is beneficial whether AI takes the shape of a chatbot or of a feature embedded in a product.

### Content Creation

Many apps that incorporate AI-enhanced features begin with content creation or manipulation, because it's such a natural fit for a large language model (LLM). If your product involves creating or modifying content, there's a strong chance that genAI can deliver a significant boost in value for your users.

#### Example: Bumble

Dating companies like Bumble want to help their users make meaningful connections with others. But many people struggle to start up new conversations once they've matched with someone. To address this pain point, Bumble created Icebreaker — a feature to autogenerate an introduction message.

![Button that says "Not sure what to say? Let's help you break the ice."](https://media.nngroup.com/media/editor/2025/03/03/bumbleaisuperpowers.png)
<sub>Source: *Nielsen Norman Group*, NN/g Team (2025).</sub>

### Summarization

In addition to producing content, generative AI can ingest vast amounts of content and summarize key points. Tech giants have led the way, launching tools to condense complex information into digestible snippets. Companies of all sizes are following suit, leveraging multimodal AI models to provide summaries of everything from documents to videos. AI can make large amounts of information easily consumable to users.

However, it's important to remember that hallucinations can occur in these summaries, especially when large amounts of text are summarized.

#### Example: Gmail

Clicking on Gmail's Summarize this email button opens a chat panel that instantly starts summarization, while allowing the user to follow up with questions. It takes entire conversations and distills them into the most important points.

![A GIF showing Google Gemini summarizing a long email into a few bullets](https://media.nngroup.com/media/editor/2025/03/03/gmail_email_summary.gif)
<sub>Source: *Nielsen Norman Group*, NN/g Team (2025).</sub>

### Basic Data Analysis

Most people find statistical calculations intimidating. Generative AI can guide users to the appropriate statistical method or even perform the calculations for them. While these tools are not yet flawless, they represent a powerful way to foster more confident, data-driven thinking among users.

#### Example: Mixpanel

Some of the first adopters of genAI were product-and-marketing-analytics software. These often contain data-heavy functionalities that their users struggle with. One such software, Mixpanel, has a feature (Spark AI) that allows users to ask questions in natural language. In response, the system produces graphics that users can further interrogate.

![A chart showing conversion rate over time by browser.](https://media.nngroup.com/media/editor/2025/03/03/mixpanelaisuperpowers.png)
<sub>Source: *Nielsen Norman Group*, NN/g Team (2025).</sub>

> **Note:** The following article is reproduced verbatim from  
> Vercel Team, *Vercel* (2025):  
> [State of AI](https://vercel.com/state-of-ai)  
> for internal educational use only (non-profit).

# State of AI

## 00.01 A survey for AI application builders

The best way to understand a tool's current state, future direction, and user impact is to ask those who build with it daily. That's why this survey targeted app builders. They're tackling today's challenges, spotting tomorrow's opportunities, and working to maximize AI's value for users.

## 00.02 Table of Contents

- Model adoption and strategy
- Applications and value creation
- Development practices and efficiency
- Priorities and organization
- Beliefs and opinions
- Conclusion

## Model adoption and strategy

### Intro

OpenAI is leading model adoption, but competition is catching up

While OpenAI remains the primary choice with 88% adoption, developers maintain relationships with multiple providers — two on average. As providers race to compete, developer loyalty is tested with 65% switching providers within six months.

### Key Insights

- Leverage abstractions that prevent provider lock-in and facilitate switching
- Review provider performance quarterly against your specific use cases
- Stay connected to rapid market changes through direct developer communities

### Builder's Takeaway

Start small, stay flexible

Architect your systems for provider mobility and model portability. Small teams are leading AI implementation, proving you don't need massive resources to succeed. The winning strategy is to build a multi-provider foundation that allows you to quickly pivot to the best solutions for your use cases as new features and capabilities emerge.

### Which LLM providers do you currently use?

- **OpenAI**: 87%
- **Anthropic**: 68%
- **Google**: 63%
- **DeepSeek**: 29%
- **xAI**: 23%
- **Groq**: 22%
- **Meta**: 12%
- **Microsoft**: 10%

**Average number of providers used**: 2

**Software as primary industry focus**: 40%

### What provider did you switch to in the last six months?

- **Google**: 31%
- **Anthropic**: 29%
- **Groq**: 11%

**Switched LLM provider in the last six months**: 60%

### Most used inference providers

- **OpenAI**: 83%
- **Anthropic**: 45%
- **Google Cloud**: 28%

## Applications and value creation

### Intro

We are past the phase of adding AI for hype

As AI adoption matures, there's a shift from basic AI integrations to real value creation. A majority of teams are using vector databases, building strong foundations for more sophisticated applications. They're prioritizing core features over chatbots, and making AI an essential part of their product's DNA.

### Key Insights

- The gap between chatbots (44%) and product features (79%) reveals a shift toward deeper AI integration
- Vector database adoption (70%) signals maturing AI infrastructure
- Website personalization (24%) remains underexplored, hinting at future opportunities

### Builder's Takeaway

Focus on how to solve fundamental product challenges with AI

While the market is young with plenty of untapped opportunities, the era of quick wins is over. Users expect more from AI now. Ask deeper questions about how AI can enhance every aspect of user experience, and make it central to your product development, not just an add-on.

> "AI is dissolving the boundaries between roles. We're seeing new product designers blend UX, UI, and code in one creative flow—thanks to tools like Vercel, v0, Uizard, and Cursor. Whether junior or senior leader, anyone can now build, test, and ship ideas independently—and that's not just efficient, it's liberating."

— Nicolas Le Pallec, CTO, EMEA — AKQA

### Development stage of AI applications

- **Basic implementation**: 42%
- **Multiple prod cases**: 25%
- **Ad hoc prod usage**: 23%

**Using a vector database**: 71%

**Running 1-2 applications in production**: 70%

### Primary application types

- **Customer facing**: 43%
- **Both equally**: 33%
- **Internal tools**: 24%

### Most common customer-facing features

- **Product AI**: 75%
- **Knowledge base / Q&A**: 60%
- **Support chatbot**: 39%
- **Website personalization**: 27%

## Development practices and efficiency

### Intro

Today's teams build high-demand AI systems through smart technical choices, not big budgets

AI teams build powerful systems on lean budgets, spending under $1,000/month. They skip costly training by using RAG, smart data sourcing, and cloud platforms to ship fast, reliable models without heavy infrastructure.

### Key Insights

- Teams optimize costs through smart architecture and augmented generation rather than custom model training
- Weekly model updates are becoming standard, pointing to rapid iteration practices supported by providers like Vercel
- Most teams pair manual testing with experience-based releases, but metric-driven evaluation is emerging

### Builder's Takeaway

Leverage existing resources to ship quickly and efficiently

The winning pattern combines cloud platforms for deployment speed, existing models for reliability, and modern frameworks for rapid development—letting teams ship AI without infrastructure overhead.

### Release process nature

- **Experience-based**: 54%
- **Hybrid approach**: 27%
- **Metrics-driven**: 19%

### Accuracy and Customization

Teams solve accuracy challenges through data strategy, not spending

Teams combine public datasets, web scraping, and customer data with RAG customization to deliver precise outputs without the overhead of custom model training.

**Don't train their own models**: 86%

### Top technical challenges in building AI features

- **Accuracy / hallucinations**: 60%
- **Latency / Performance**: 23%
- **Cost management**: 23%

### Model customization strategy

- **RAG / Vector databases**: 60%
- **No customization**: 20%
- **Fine-tuning**: 12%

**Use manual testing to evaluate model outputs**: 70%

### Most used data sources to train/enhance AI models

- **Proprietary data**: 48%
- **Customer data**: 44%
- **Public datasets**: 40%
- **Web scraping**: 40%
- **Synthetic data**: 23%

### Types of documents processed for RAG

- **Markdown and Text**: 60%
- **PDFs**: 60%
- **Web pages**: 42%
- **Database records**: 41%
- **Code repositories**: 22%
- **Other**: 10%

## Priorities and organization

### Intro

Tools over hiring

Many dedicate meaningful tech budget (over 15%) to AI, but aren't planning to grow dedicated AI teams. They're finding ways to build sophisticated AI features by empowering existing teams with better tools and clear objectives.

### Key Insights

- Teams choose lean integration over specialized departments
- Existing product teams drive AI innovation
- Priorities are being balanced between building new features and scaling existing ones

### Builder's Takeaway

AI development is entering a pragmatic phase

Building successful AI features doesn't necessarily require a specialized department. Focus on high-impact use cases while keeping team structure lean. The opportunity lies in finding where AI adds real value and executing efficiently with available resources.

> "At BCG X, we are excited about the transformative potential of AI and the ecosystem of AI-powered tools reshaping creativity, digital solutions, and customer experiences. By embracing cutting-edge AI technologies we're empowering our teams to work smarter and faster."

— Dr. Jan Ittner, Global Engineering Chapter Lead — BCG X

### Top AI priorities for the next 6 months

- **Launching new use cases**: 54%
- **Scaling existing solutions**: 42%

### Budget allocation for AI (% of tech budget)

- **5-15% budget**: 37%
- **<5% budget**: 27%
- **16-30% budget**: 24%

### AI team structure

- **No dedicated AI team**: 45%
- **Other**: 29%
- **Embedded in product teams**: 27%

### AI leadership structure

- **No specific AI leadership**: 57%
- **Part of tech leadership**: 31%
- **Dedicated AI executives**: 12%

### Which AI-related roles are you planning to hire?

- **Software Engineers**: 48%
- **No planned hiring**: 41%
- **ML engineers**: 25%

## Beliefs and opinions

### Intro

The AI market has found its sweet spot between hype and real impact

Teams think current AI tools are overhyped, but they expect AI to significantly impact their industry within 12 months. They're excited about the future but grounded in the present.

### Key Insights

- Teams believe in AI's future while staying realistic about current tools
- Open source and fine-tuning are proving useful, but aren't game-changers yet
- Everyone's preparing for major advancements in the next year

### Builder's Takeaway

Build with what works now, but design for what's coming

Big changes are ahead, even if we're not there yet. Be aware of the current limitations and challenges, while remaining optimistic about the transformative potential of AI.

### Survey Ratings (out of 10)

- **Open source models are production-ready**: 6.5/10
- **Fine tuning provides meaningful improvements**: 5.3/10
- **Current AI tools are overhyped**: 6.4/10
- **AI will impact my industry within 12 months**: 7.7/10

## Conclusion

### Conclusion

The AI landscape is evolving fast

There is strong belief in AI's potential. While OpenAI is the leading provider, developers are actively testing alternatives and focusing on real-world value. Priorities are shifting toward customer-facing features, but challenges like model accuracy and cost remain key concerns. Success requires careful evaluation, strategic planning, and a flexible implementation to adapt to changes. We look forward to continued innovations this year and beyond.

### Survey methodology

- **Objective**: Understanding what people are building with AI and how they're building it
- **We shared two surveys**, one in Q4 of 2024 and one in Q1 of 2025 to map how responses change over time
- **656 applications builders were surveyed**, sourced from the Vercel community, X.com, and AI community newsletters

> **Note:** The following article is reproduced verbatim from  
> Sopra Steria Team, *Sopra Steria* (2025):  
> [Building the Future-Ready Workforce: AI Fluency Is the New Literacy](https://www.soprasteria.co.uk/insights/blogs/details/building-the-future-ready-workforce-ai-fluency-is-the-new-literacy)  
> for internal educational use only (non-profit).

# Building the Future-Ready Workforce: AI Fluency Is the New Literacy

As AI reshapes our world faster than we imagined, the question we face isn't whether we need an AI-ready workforce — it's how quickly we can build one that's inclusive, imaginative, and equipped for what's next.

We believe this shift is about reimagining the entire talent lifecycle, from nursery to boardroom. That's why, when asked to contribute to techUK's spotlight on the UK's AI ecosystem, I brought together colleagues from across disciplines to co-create our collective view. What emerged was clear: technical skills for the future are vital, but they're not enough for an AI world.

AI isn't the future. It's here — and accelerating.

"The rapid adoption and rate of change is phenomenal," said David Wilson, a technical consultant. "When I first started exploring AI, I thought AGI was 20 years away. Now I think it could be five."

This acceleration is already transforming job markets. The World Economic Forum's Future of Jobs Report 2025 shows the most in-demand skills are not technical or literacy. Analytical thinking, creative thinking, resilience, and curiosity top the list. These are not 'nice-to-haves' — they are critical for navigating an AI-infused economy.

As AI continues to evolve and take on more tasks, the role of human input is shifting. In this new landscape, meaning and purpose are becoming the key motivators- especially for younger generations, who may be asking "What's the point?". AI can feel like just another obstacle, but those who are grounded in a strong sense of why will be the ones who adapt, thrive and find their place.

## Creativity and STEM

One of the most thought-provoking tensions that emerged in our workshop was between investing in creativity versus technical STEM proficiency. Some argued, reasonably, that AI development demands strong foundations in maths, data science, and engineering. As one colleague put it, "In a tight fiscal environment, prioritising vocational STEM training offers more immediate return."

But others challenged that view. "We don't need more professional artists," said Joanna Finlay, Consulting Manager, "but we do need kids to do music, dance, art — because it makes their brains more agile and imaginative."

I agree. These creative capacities are what AI can't (yet) replicate — but exactly what we need to design the ethical, intuitive, and inclusive tech of the future.

Consulting Manager Mark Henderson captured this perfectly:

"An AI-ready workforce might actually be 80% AI. So the human 20%? That better be exceptional. It had better be creative, ethical, and curious — or we'll just be dominated by the tools we've built."

Collectively we explored a future that isn't STEM or arts — maybe it's Createch: the fusion of creativity and technology. As Charles Landry, a leading international authority on the use of imagination and creativity in urban change, says, "Distinctions between 'cultural', 'creative' and 'digital' enterprises are fast eroding." This interplay must start early — and it must be deliberate.

## Start young. Upskill wide. Embed learning for life.

Our collective view is simple: we need to start early, learn differently, and adapt constantly.

"AI should be taught at primary school," said Jonathan Cave, Consulting Manager. "It's as important now as maths and english." Fellow Consulting Manager, Selina Satchell agreed: "There's a chunk of development before primary school — nursery even — where kids are already engaging with AI-powered tools."

But education alone won't bridge the gap. We must rethink learning across the workforce. That means:

- **Accessible reskilling** now for those at risk of being left behind.
- **Just-in-time training** to keep pace with evolving tools.
- **Critical thinking and ethical reasoning** as core competencies.

We also need to govern AI learning itself. "Who decides what's fact in an AI-generated world, and what should be taught?" asked Jonathan. "It raises important questions about how we teach truth, trust, and technology in the age of AI."

Our call to action: Invest in humans as well as the tech.

AI is already changing the way we work and live. To stay ahead, the UK must invest in people — not just technology.

Here's what we need to do:

- **Start early with AI education**, creativity and STEM, making sure children learn how to use and understand AI from the start.
- **Help businesses give all workers access** to just-in-time on-the-job learning, so no one gets left behind.
- **Make AI learning part of everyday life**, not just something you do at the start of your career.
- **Teach people to think critically** about AI, so they can use it wisely and ask the right questions.
- **Create a holistic approach to education**, including preparing society for the impacts of AI, and not just the skills in isolation.

The AI era demands more than technical know-how. It demands human ingenuity. Let's build a workforce that's technically confident, creatively alive, and critically prepared for what's next.

> **Note:** The following article is reproduced verbatim from  
> Google Team, *Grow with Google* (2025):  
> [In-demand AI courses for today's workforce](https://grow.google/ai/)  
> for internal educational use only (non-profit).

# In-demand AI courses for today's workforce

AI is changing how we work, offering new ways to make decisions, solve problems, and be more productive and creative. Learn how to harness these benefits with practical AI training and tools from Grow with Google.

## Build essential skills with AI training

Flexible, online training programs designed to help you supercharge your work or business with AI.

### Prompting Essentials
**COURSE • 6 HOURS**

Ready to get more out of AI? Learn how to use AI effectively by writing clear and specific instructions called prompts. In 5 easy steps you'll boost your productivity and make AI work for you.

### AI Essentials
**COURSE • 5 HOURS**

New to AI? Learn how AI can assist, empower, and inspire you. Use generative AI tools to speed up daily tasks and develop new ideas and content.

### Grow Your Business with AI
**WORKSHOP • 1 HOUR**

Learn the basics of AI and how Google AI-powered tools can help small businesses be more efficient, enhance customer experiences, and drive growth.

### Generative AI for Educators
**COURSE • 2 HOURS**

Learn how to use generative AI tools to help you save time on everyday tasks, personalize instruction, enhance lessons and activities in creative ways, and more.

### Make AI Work for You
**COURSE • 1 HOUR**

Tired of your endless to-do list? Unlock fresh ideas and eliminate repetitive work with AI. Our YouTube course, Make AI Work for You, brings you helpful tutorials from Google experts and business owners – with new videos arriving weekly.

### AI for Students
**Training & Tools**

Feeling overwhelmed with coursework? Our expert-led training teaches you how to make AI your ultimate study buddy. Plus, students get free access to Google's most advanced AI tools for the entire school year.

## The growing demand for AI

- **79%** of workers say that AI skills will broaden their job opportunities
- **21x** increase in job postings mentioning AI technologies
- **1.75** average hours saved each day reported by employees who use generative AI

## GOOGLE CAREER CERTIFICATES NOW WITH AI TRAINING

### Earn a Google Career Certificate and learn practical, field-specific AI skills along the way

Google Career Certificates are offered in data analytics, project management, cybersecurity, digital marketing & e-commerce, IT support, and UX design. Taught by experts at Google, these industry-leading programs are designed to put you on the fast track to jobs in high-paying fields.

Each certificate now features practical AI training and hands-on activities to help you use AI in your field. Harness the benefits of AI to boost your productivity and creativity, unlock opportunities in your career, and stand out among your peers.

## Transform the way you learn with AI tools

Interactive and personalized tools designed to help you develop skills and uncover new possibilities for your work and career.

### Career Dreamer
Discover how your unique life experiences can translate into valuable skills that employers need. Career Dreamer is a playful, simple way to explore new career possibilities.

### Interview Warmup
Prepare for your next interview with confidence. Interview Warmup lets you practice answering real questions and uses AI to analyze your responses and provide tailored feedback.

### NotebookLM
Businesses like Heritage Bikes & Coffee use NotebookLM to solve everyday challenges and save time - and you can, too. Upload your own documents, ask questions, and listen to Audio Overviews to explore your content in a new way.

## Empowering more people with AI

### Testimonials

> "I was self-employed for 13 years and I'd never really done any interviews. Using Interview Warmup I learned how to answer questions in a much more professional way. It's been a big confidence boost."
> 
> — LE'MONT C., Google Career Certificate graduate

> "I feel much more confident in my ability to leverage generative AI tools effectively and responsibly. The hands-on activities and real-world examples were particularly helpful in solidifying my understanding."
> 
> — SUSAN B., Google Prompting Essentials graduate

> "The AI Essentials course was instrumental in equipping me with a strong foundation in leveraging AI for daily tasks. I've achieved a dramatic improvement in my daily efficiency, freeing up time for more strategic tasks."
> 
> — CHRISTIAN W., Google AI Essentials graduate

## Frequently asked questions

### Is an AI certificate worth it?
### Does AI require coding?
### Can I learn AI on my own?
### Which is the best AI course for beginners?
### How long will it take to learn AI?
### What is the difference between AI Essentials and Prompting Essentials?
### Is Google offering free AI courses?

> **Note:** The following article is reproduced verbatim from  
> Rick Dakan and Joseph Feller, *Ringling College of Art + Design* (2025):  
> [Framework for AI Fluency](https://ringling.libguides.com/ai/framework)  
> for internal educational use only (non-profit).

# Framework for AI Fluency (Practical Summary Document), Version 1.1

## About this Document

The Framework for AI Fluency summarized in this document has emerged from an ongoing research collaboration between Prof. Rick Dakan from the Ringling College of Art and Design, Florida, and Prof. Joseph Feller from the Cork University Business School, University College Cork, Ireland. Dakan and Feller's work explores the intersection between (1) Human Creativity and Innovation, (2) Generative AI technologies (GenAI), and (3) Learning & Teaching in Higher Education.

The framework has also been (and continues to be) informed by the ongoing design and delivery of student courses, as well as faculty seminars and workshops, at both the Ringling College of Art and Design and the Cork University Business School, in the 2023/2024, 2024/2025, and 2025/2026 Academic Years.

This document presents an overview of the framework as a practical tool that is designed to inform discourse and practice in higher education on curriculum and assessment design, academic policy setting, student employability and career coaching, and similar topics in the context of AI (and particularly GenAI) digital disruption.

Although primarily aimed at higher education, we imagine that the framework in this form will also benefit other educational levels, and indeed organizations more widely addressing the challenges and opportunities of GenAI.

## Framework Overview

The Framework for AI Fluency describes the interconnected competencies needed to use AI in creative, innovative, and problem solving work. Rather than viewing AI merely as an efficiency engine, the framework recognizes the potential for AI to act as an authentic thinking partner for doing meaningful cognitive work, while acknowledging that this potential can only be realized through the development and performance of specific human competencies.

We define AI Fluency as the ability to work effectively, efficiently, ethically, and safely within emerging modalities of Human-AI interaction. In its current version, the framework identifies three modalities of interaction observable in the current state-of-the-art:

### Modality 1: Automation (AI Performs Human-Defined Task)

- AI performs tasks independently, but based on direct human instructions (e.g. in response to a prompt).
- This modality is particularly useful for improving the efficiency of repetitive, time-consuming, or data-intensive tasks.
- Requires clear task definition and quality control measures.
- Examples: Emails, summaries, social media posts, basic coding.

### Modality 2: Augmentation (AI and Human Perform Task Collaboratively)

- AI and human co-define and co-execute tasks in an iterative way, collaborating towards an end goal
- This modality focuses on enhancing human creativity rather than replacing it through the addition of an AI thinking partner.
- Involves a dynamic interplay between human and AI contribution.
- Examples: Writing stories, essays, research papers, complex coding tasks.

### Modality 3: Agency (Human Configures AI to Perform Tasks Independently)

- Human configures AI to independently perform future tasks (including for others) on behalf of the user.
- This modality defines the characteristics and future behavior of an AI, rather than a specific task.
- Requires sophisticated understanding of AI capabilities and limitations.
- Examples: Interactive game characters, tutors, chatbots.

Human-AI interactions often bridge multiple modalities, and practitioners often move between contexts even within single projects or workflows.

**The framework identifies four core competencies (described in section 3) that enable practitioners to:**

- Make appropriate decisions about if, when, and how to use AI tools,
- Effectively communicate desired outputs and behaviours to AI systems
- Accurately assess the quality and appropriateness of AI outputs and behaviours,
- Ensure ethical practice, transparency and accountability.

We believe the framework offers several key advantages:

- **Platform and Technology Agnostic**: Independent of specific tools or platforms, and is adaptable to emerging and rapidly evolving technologies and use cases.
- **Contextual and Flexible**: Characterizing effective action rather than prescribing rigid processes, and is compatible with other skills taxonomies in a variety of professional contexts.
- **Ethics-Centered**: Treats ethical considerations as fundamental, and recognizes that responsible and safe AI use is as important as responsible and safe AI design.

## Core AI Competencies ("The 4 D's")

The four core competencies describe the interconnected human skills, knowledge and values that enable effective, efficient, ethical, and safe Human-AI interaction.

### Delegation - Creative vision and selection of the right AI tools and techniques to realize that vision.

**Delegation** refers to the ability to identify when and how to use AI tools and modalities effectively in creative and problem-solving processes. It involves understanding the capabilities and limitations of various AI technologies and making informed decisions about when to use AI for automation, augmentation, or independent agent-mediated experiences.

**Subcategories:**

**a) Goal and Task Awareness:**
- Envisioning an effective goal for a project.
- Understanding the nature and requirements of the task(s) towards the defined goal.
- Ability to analyze and deconstruct a task into AI, human, and collaborative components.
- Necessary for effective integration of AI into creative workflows.

**b) Platform Awareness:**
- Understanding the capabilities and limitations of current AI tools.
- Knowledge of various AI platforms and their specific strengths and limitations in relation to the project's goal.
- Ability to evaluate AI tools based on project requirements, budget, operational and regulatory needs.
- Necessary for selecting the optimal AI tools for specific tasks.

**c) Task Delegation:**
- Balancing AI and human capabilities throughout a project to best realize the creative vision.
- Understanding the different affordances of each modality (Automation, Augmentation, Agency).
- Ability to assign project tasks to human and AI tools optimally.
- Necessary for successful collaboration between human and AI in creative processes.

### Description - Effectively describing a vision and/or tasks to prompt useful AI behaviors and outputs.

**Description** encompasses the skills needed to effectively communicate ideas, requirements, constraints, and other aspects of creative visions to AI systems. It involves crafting clear, specific, and well-structured prompts (using a wide range of prompting techniques) and other elements that guide and enable AI tools to produce desired behaviors and outputs.

**Subcategories:**

**a) Product Description:**
- Prompting to define desired output.
- Ability to clearly articulate desired characteristics, features, and qualities of the final AI-generated output.
- Skill in translating creative vision into explicit, AI-understandable terms.
- Crucial for guiding AI tools to produce results aligned with the creator's intentions.

**b) Process Description:**
- Dialogic prompting to produce effective iterative collaboration.
- Ability to engage in dynamic, back-and-forth communication with AI tools.
- Skill in breaking down complex tasks into a series of smaller, manageable prompts.
- Essential for guiding AI through multi-step creative processes aligned with the human collaborator.

**c) Performance Description:**
- Directive prompting to define future AI behaviors and enable positive user experience.
- Ability to define how AI-generated content or systems should behave or interact with users.
- Skill in anticipating user needs and translating them into guidelines for AI behavior.
- Critical for enabling future AI-driven behaviors that are aligned with the human's vision and values.

### Discernment - Accurately assessing the usefulness of AI outputs

**Discernment** involves the critical evaluation of AI-generated outputs, understanding their quality, relevance, potential biases, and other salient characteristics. It also includes the ability to iterate and refine the collaborative process with AI tools.

**Subcategories:**

**a) Product Discernment:**
- Evaluating output quality and identifying ways to improve it.
- Ability to critically assess the quality, relevance, and effectiveness of AI-generated content.
- Skill in identifying strengths and weaknesses in AI outputs.
- Crucial for maintaining high standards in AI-assisted creative work.

**b) Process Discernment:**
- Assessing if the human-AI collaborative dynamic is fruitful or not and how to improve it.
- Ability to evaluate the effectiveness of the human-AI collaborative process.
- Skill in identifying which aspects of human-AI interactions are most beneficial and where improvements can be made.
- Essential for optimizing the use of AI tools in creative collaborative work.

**c) Performance Discernment:**
- Evaluating if AI-driven independent behaviors enable positive user experiences and how to better direct the AI to improve outcomes.
- Ability to assess the effectiveness of AI systems in independent, user-facing scenarios.
- Skill in gathering and interpreting human feedback to refine and ensure intended AI-driven behaviors and experiences.
- Essential for designing user experiences aligned with the project's vision and values.

### Diligence - Taking responsibility and vouching for final products created using AI

**Diligence** refers to the responsible use of AI, including ethical considerations, transparency about AI use, and taking accountability for the final products created with AI assistance.

**Subcategories:**

**a) Creation Diligence:**
- Responsible use of AI tools, maintaining ethical and legal best practices, awareness of biases, flaws, stakeholder impacts, and other externalities
- Understanding and applying ethical principles throughout the AI-assisted creative process.
- Ability to identify and mitigate potential biases and ethical risks in AI-generated content.
- Crucial for ensuring responsible and socially conscious use of AI in creative work.

**b) Transparency Diligence:**
- Transparency and accountability when distributing the end product.
- Understanding of audience, industry, and legal expectations and norms around AI-generated content.
- Skill in clearly communicating the nature of AI involvement in the process.
- Essential for maintaining trust and integrity when distributing AI-assisted work.

**c) Deployment Diligence:**
- Taking responsibility for verifying and vouching for AI-assisted outputs, including thorough fact-checking, testing for accuracy, and validating claims.
- Implementing appropriate safety checks and testing procedures before releasing AI-assisted work.
- Understanding, managing, and assuming responsibility for potential risks and impacts of deployed AI-assisted content and/or agents.
- Essential for ensuring the quality, safety, and reliability of content and/or agents created through Human-AI interaction.

## Diligence Statement

*Diligence Statement: In the creation of this document, we used Claude 3.5 Pro to assist in text creation and refinement. We affirm that all AI-generated content underwent thorough vetting, editing, and curation by the human co-authors. The final document accurately reflects our understanding, expertise, and intended meaning. While AI tools were instrumental in the writing process, we maintain full responsibility for the content, its accuracy, and its presentation. This disclosure is made in the spirit of transparency and to acknowledge the evolving role of AI in content creation and other intellectual work.*

> **Note:** The following article is reproduced verbatim from  
> Paweł Huryn, *Substack* (2025):  
> [If I had to learn AI PM again, I would start here](https://substack.com/@huryn/note/c-137686625)  
> for internal educational use only (non-profit).

# If I had to learn AI PM again, I would start here (new, extended edition)

## 1. Basic Concepts

Start with understanding what an AI PM is and the fundamentals of AI product management.

Next, it makes no sense to dive deep into statistics, Python, or loss functions. Instead, read about Transformers, and LLMs to understand the core technologies.

## 2. Prompt Engineering

Free resources for learning prompt engineering:

- GPT-4.1 Prompting Guide
- Anthropic Prompt Engineering
- Prompt Engineering by Google
- System Prompt Analysis for Claude 4
- Anthropic Prompt Generator
- Anthropic Prompt Library
- Prompt Engineering Course By Anthropic

## 3. Fine Tuning

Learn by doing. Focus on practical applications rather than deep technical theory.

## 4. RAG (Retrieval-Augmented Generation)

Understand how to build systems that combine retrieval with generation for more accurate and contextual responses.

## 5. AI Product Strategy

Learn how to develop and execute AI product strategies that align with business goals.

## 6. AI Product Development

Understand the unique challenges and opportunities in developing AI-powered products.

## 7. AI Product Launch

Learn best practices for launching AI products successfully.

## 8. AI Product Growth

Understand how to scale and grow AI products effectively.

The full AI PM learning guide with extra resources is available for comprehensive learning.

## Sources

<Card title="Reference Materials">
  <ul>
    <li><strong>Anthropic Claude Documentation:</strong> <a href="https://docs.anthropic.com/en/docs/overview">https://docs.anthropic.com/en/docs/overview</a></li>
    <li><strong>Claude API Reference:</strong> <a href="https://docs.anthropic.com/en/api">https://docs.anthropic.com/en/api</a></li>
    <li><strong>Prompt Engineering Guide:</strong> <a href="https://docs.anthropic.com/en/docs/prompt-engineering">https://docs.anthropic.com/en/docs/prompt-engineering</a></li>
    <li><strong>Tool Use Documentation:</strong> <a href="https://docs.anthropic.com/en/docs/agents-and-tools/tool-use">https://docs.anthropic.com/en/docs/agents-and-tools/tool-use</a></li>
    <li><strong>Safety and Trust:</strong> <a href="https://trust.anthropic.com/">https://trust.anthropic.com/</a></li>
  </ul>
</Card>

## Figures

<Card title="Transformer Architecture">
  <Frame>
    <img src="/assets/concepts/transformer-pipeline.webp" alt="Diagram showing the transformer architecture pipeline" />
  </Frame>
  <figcaption>Credit: synthesized from multiple sources</figcaption>
</Card>

<Card title="AI Model Scaling">
  <Frame>
    <img src="/assets/concepts/transformer-architecture.webp" alt="Visualization of transformer architecture components" />
  </Frame>
</Card>

